{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ff9d18d0",
        "690a3fce",
        "301f1e1a",
        "42b41616"
      ],
      "authorship_tag": "ABX9TyPS2JKVIQnfhwTez2+FU1lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerioMatos75/3D_Fusion_AI/blob/main/3D_Fusion_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b99b3e8"
      },
      "source": [
        "%pip install numpy opencv-python-headless scikit-image trimesh\n",
        "print(\"Bibliotecas instaladas com sucesso!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cfa0cbc"
      },
      "source": [
        "# Task\n",
        "Refactor the provided Python code in Google Colab to implement a 3D reconstruction pipeline using the Visual Hull and Marching Cubes algorithms, based on the steps outlined in the `Readme.md` file. The pipeline should take multiple silhouette images as input, reconstruct a 3D model, and export it as a `.glb` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67660f45"
      },
      "source": [
        "## Preparar o ambiente e carregar dados\n",
        "\n",
        "### Subtask:\n",
        "Adaptar o carregamento de imagens para lidar com múltiplas vistas/silhuetas (seja carregando vários arquivos ou simulando-os).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dc95cea"
      },
      "source": [
        "%pip install trimesh\n",
        "print(\"Biblioteca trimesh instalada com sucesso!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd68770c"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "print(\"Por favor, carregue o arquivo .ZIP contendo as silhuetas e o metadata.json\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assume a single zip file is uploaded\n",
        "if uploaded:\n",
        "    zip_file_name = list(uploaded.keys())[0]\n",
        "    print(f\"Arquivo '{zip_file_name}' carregado.\")\n",
        "\n",
        "    # Define the path where the zip file is located in the Colab environment\n",
        "    # files.upload() places the file in the current working directory (/content/)\n",
        "    zip_file_path = os.path.join('/content/', zip_file_name)\n",
        "\n",
        "    # Create a directory to extract files into\n",
        "    extract_path = '/content/uploaded_data'\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    print(f\"Tentando descompactar '{zip_file_name}' para '{extract_path}'...\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Check if the uploaded file is indeed a zip file before attempting to open\n",
        "        if zipfile.is_zipfile(zip_file_path):\n",
        "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "            print(f\"Arquivo descompactado com sucesso para '{extract_path}'.\")\n",
        "\n",
        "            # Now, let's look for the metadata.json and list other files\n",
        "            metadata_path = os.path.join(extract_path, 'metadata.json')\n",
        "            if os.path.exists(metadata_path):\n",
        "                print(\"\\nArquivo metadata.json encontrado:\")\n",
        "                try:\n",
        "                    with open(metadata_path, 'r') as f:\n",
        "                        metadata = json.load(f)\n",
        "                    print(\"Conteúdo do metadata.json (primeiros itens):\")\n",
        "                    # Display first few items or structure\n",
        "                    import pprint\n",
        "                    pprint.pprint(metadata)\n",
        "\n",
        "                    # Store metadata and extracted file path for later use\n",
        "                    uploaded_metadata = metadata\n",
        "                    extracted_files_path = extract_path\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao ler ou analisar metadata.json: {e}\")\n",
        "                    uploaded_metadata = None\n",
        "                    extracted_files_path = extract_path # Still keep path to other files\n",
        "\n",
        "            else:\n",
        "                print(\"\\nArquivo metadata.json NÃO encontrado no ZIP.\")\n",
        "                uploaded_metadata = None\n",
        "                extracted_files_path = extract_path # Still keep path to other files\n",
        "\n",
        "\n",
        "            print(\"\\nOutros arquivos descompactados (limitado a 10 para brevidade):\")\n",
        "            # List files in the extracted directory (limit output)\n",
        "            count = 0\n",
        "            for root, dirs, files_in_dir in os.walk(extract_path):\n",
        "                for file in files_in_dir:\n",
        "                    if count < 10:\n",
        "                        print(os.path.join(root, file).replace(extract_path, '')) # Print path relative to extracted_path\n",
        "                        count += 1\n",
        "                    else:\n",
        "                        print(\"...\")\n",
        "                        break\n",
        "                if count >= 10:\n",
        "                    break\n",
        "\n",
        "\n",
        "        else:\n",
        "             print(f\"Erro: O arquivo carregado '{zip_file_name}' não parece ser um arquivo ZIP válido.\")\n",
        "             extracted_files_path = None\n",
        "             uploaded_metadata = None\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro inesperado durante a descompactação ou processamento: {e}\")\n",
        "        extracted_files_path = None\n",
        "        uploaded_metadata = None\n",
        "\n",
        "else:\n",
        "    print(\"\\nNenhum arquivo foi carregado.\")\n",
        "    extracted_files_path = None\n",
        "    uploaded_metadata = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "583339f1"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure\n",
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "import json\n",
        "\n",
        "# --- Function Definitions (Moved from Cell c3d08790) ---\n",
        "\n",
        "# Modified load_images to read from a directory\n",
        "def load_images_from_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from a specified directory. Assumes images are directly in the directory.\n",
        "\n",
        "    Args:\n",
        "        directory_path: The path to the directory containing the image files.\n",
        "\n",
        "    Returns:\n",
        "        A list of loaded grayscale images, and a list of their filenames, or empty lists if an error occurs or no images found.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    print(f\"Loading images from directory: {directory_path}...\")\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print(f\"Error: Directory not found: {directory_path}\")\n",
        "        return images, image_filenames # Return empty lists\n",
        "\n",
        "    try:\n",
        "        # List all files in the directory\n",
        "        all_files = os.listdir(directory_path)\n",
        "        # Filter for common image file extensions (you might need to adjust this list)\n",
        "        image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"Warning: No image files found in directory: {directory_path}\")\n",
        "            return images, image_filenames # Return empty lists\n",
        "\n",
        "        # Sort files to maintain a consistent order, important for matching with metadata\n",
        "        image_files.sort()\n",
        "\n",
        "        for file_name in image_files:\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "            # Read image in grayscale\n",
        "            img_grayscale = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if img_grayscale is None:\n",
        "                print(f\"Warning: Could not load image file: {file_name}\")\n",
        "                continue\n",
        "\n",
        "            images.append(img_grayscale)\n",
        "            image_filenames.append(file_name)\n",
        "            print(f\"Successfully loaded {file_name}.\")\n",
        "\n",
        "        print(f\"Finished loading {len(images)} images.\")\n",
        "        return images, image_filenames\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during image loading from directory: {e}\")\n",
        "        return [], [] # Return empty lists in case of error\n",
        "\n",
        "\n",
        "# Modified process_silhouettes to potentially include cleaning and previews\n",
        "def process_silhouettes(images, show_previews=False):\n",
        "    \"\"\"\n",
        "    Extracts silhouettes from a list of grayscale images with error handling,\n",
        "    applies basic morphological operations for cleaning, and optionally displays previews.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "        show_previews: If True, display the original grayscale image and the extracted silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks), or None if an error occurs.\n",
        "    \"\"\"\n",
        "    silhouettes = []\n",
        "    print(\"Processing silhouettes...\")\n",
        "    if not images:\n",
        "        print(\"No images provided for silhouette processing.\")\n",
        "        return silhouettes\n",
        "    try:\n",
        "        # Define kernel for morphological operations\n",
        "        # A small kernel is usually sufficient for minor cleaning\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "        for i, img_grayscale in enumerate(images):\n",
        "            # Ensure image is valid before processing\n",
        "            if img_grayscale is None or img_grayscale.size == 0:\n",
        "                print(f\"Warning: Skipping processing for invalid image at index {i}.\")\n",
        "                continue\n",
        "\n",
        "            # Apply binary inverse thresholding\n",
        "            # Assuming the silhouettes from the zip are already binary (0 or 255)\n",
        "            # We can still apply thresholding as a safety check or to ensure binary values\n",
        "            # If images are already perfect binary, thresholding at a midpoint like 127 or 0.5 (if float) is needed.\n",
        "            # Given the previous processing, let's assume thresholding at 240 is still relevant if input wasn't perfectly binary.\n",
        "            _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "            # --- Apply morphological operations for cleaning ---\n",
        "            # Optional: Erosion followed by Dilation (Opening) to remove small objects/noise\n",
        "            # Optional: Dilation followed by Erosion (Closing) to close small holes\n",
        "            # The parameters (iterations) might need tuning based on the noise level\n",
        "            # silhouette = cv2.erode(silhouette, kernel, iterations=1)\n",
        "            # silhouette = cv2.dilate(silhouette, kernel, iterations=1)\n",
        "            # Optional: Close small holes\n",
        "            # silhouette = cv2.dilate(silhouette, kernel, iterations=1)\n",
        "            # silhouette = cv2.erode(silhouette, kernel, iterations=1)\n",
        "            # --- End of morphological operations ---\n",
        "\n",
        "\n",
        "            silhouettes.append(silhouette)\n",
        "            if show_previews:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.title(f'Original Image {i+1} (Grayscale)')\n",
        "                plt.imshow(img_grayscale, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.title(f'Silhouette {i+1} Extracted and Cleaned')\n",
        "                plt.imshow(silhouette, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "        print(f\"Finished processing {len(silhouettes)} images and extracted silhouettes.\")\n",
        "        return silhouettes\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during silhouette processing: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Modified project_voxel_to_silhouette to use camera parameters from metadata\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, camera_data, volume_bounds, grid_size):\n",
        "    \"\"\"\n",
        "    Projects a 3D voxel coordinate onto the 2D plane of a silhouette using camera parameters.\n",
        "\n",
        "    Args:\n",
        "        voxel_coords: Tuple (x, y, z) integer indices of the voxel in the grid.\n",
        "        silhouette_shape: Tuple (height, width) of the silhouette image.\n",
        "        camera_data: Dictionary containing camera pose information ('position', 'lookAt', 'up').\n",
        "        volume_bounds: Dictionary defining the world coordinates bounds of the volume.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "\n",
        "    Returns:\n",
        "        Tuple (proj_y, proj_x) pixel coordinates or (None, None) if projection is invalid.\n",
        "    \"\"\"\n",
        "    # Convert voxel grid coordinates (integers) to world coordinates (floats)\n",
        "    # Note: This assumes a linear mapping from grid index to world space within bounds\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    # Create the 3D point in world coordinates\n",
        "    point_3d_world = np.array([voxel_world_x, voxel_world_y, voxel_world_z, 1.0]) # Homogeneous coordinates\n",
        "\n",
        "    # --- Calculate Camera View Matrix (World to Camera) ---\n",
        "    # Using camera position, lookAt, and up vectors\n",
        "    camera_position = np.array([camera_data['position']['x'], camera_data['position']['y'], camera_data['position']['z']])\n",
        "    look_at = np.array([camera_data['lookAt']['x'], camera_data['lookAt']['y'], camera_data['lookAt']['z']])\n",
        "    up_vector = np.array([camera_data['up']['x'], camera_data['up']['y'], camera_data['up']['z']])\n",
        "\n",
        "    # Calculate the camera's local axes\n",
        "    forward = (look_at - camera_position)\n",
        "    forward /= np.linalg.norm(forward)\n",
        "    right = np.cross(forward, up_vector)\n",
        "    right /= np.linalg.norm(right)\n",
        "    # Recalculate up vector to ensure it's orthogonal to forward and right\n",
        "    up = np.cross(right, forward)\n",
        "\n",
        "    # Construct the view matrix\n",
        "    # This matrix transforms points from world space to the camera's local space\n",
        "    view_matrix = np.identity(4)\n",
        "    view_matrix[:3, 0] = right\n",
        "    view_matrix[:3, 1] = up\n",
        "    view_matrix[:3, 2] = -forward # Cameras look down their negative Z axis\n",
        "    view_matrix[:3, 3] = -np.dot(view_matrix[:3, :3], camera_position) # Translation\n",
        "\n",
        "    # --- Calculate Projection Matrix (Camera to Clip Space) ---\n",
        "    # This is a placeholder for a perspective projection matrix.\n",
        "    # A real scenario would need focal length, image dimensions, field of view, etc.\n",
        "    # For now, let's use a simplified orthographic-like projection scaled to image dimensions\n",
        "    # based on the assumption that the camera parameters define a view volume.\n",
        "    # This is still an approximation, but it uses the camera's orientation.\n",
        "    # A proper implementation would require intrinsic camera parameters.\n",
        "\n",
        "    # Let's try a simplified approach based on mapping the view frustum defined by camera pose\n",
        "    # to the image plane. This requires assumptions about the camera's field of view.\n",
        "    # Given the metadata structure (position, lookAt, up), we can infer the camera's orientation\n",
        "    # but not intrinsic parameters.\n",
        "\n",
        "    # Alternative simplified projection: Transform point to camera space, then scale based on image size.\n",
        "    point_3d_camera = np.dot(view_matrix, point_3d_world)\n",
        "\n",
        "    # Assuming a simple mapping from camera space X, Y to image U, V, scaled by image dimensions.\n",
        "    # This is still a highly simplified projection without a proper perspective matrix.\n",
        "    # The scaling factors here are placeholders and would ideally come from camera intrinsics.\n",
        "    # Let's try to map the camera space coordinates to pixel coordinates based on\n",
        "    # an assumed field of view or mapping from world bounds.\n",
        "\n",
        "    # Given the metadata provides position and lookAt, we can orient the camera.\n",
        "    # The projection itself still needs intrinsic parameters (focal length, principal point).\n",
        "    # Since we don't have intrinsics, a perfect perspective projection isn't possible.\n",
        "    # Let's revert to a simplified projection that at least respects the camera's orientation\n",
        "    # and tries to map the world bounds to the image plane based on the camera's view.\n",
        "    # This is complex without intrinsics.\n",
        "\n",
        "    # Let's reconsider the simplified projection but attempt to align it better with\n",
        "    # the camera's orientation derived from position/lookAt/up.\n",
        "    # We can project the 3D point onto a plane perpendicular to the camera's viewing direction\n",
        "    # and then map that 2D point to image coordinates.\n",
        "\n",
        "    # Vector from camera position to point\n",
        "    vec_to_point = point_3d_world[:3] - camera_position\n",
        "    # Component of vector along forward direction\n",
        "    dist_along_forward = np.dot(vec_to_point, forward)\n",
        "    # Projected point on the view plane (in world coordinates)\n",
        "    projected_point_3d_world = camera_position + vec_to_point - dist_along_forward * forward\n",
        "\n",
        "    # Now map the projected_point_3d_world onto the 2D image plane in the camera's coordinate system.\n",
        "    # We need to express projected_point_3d_world relative to the view plane's origin (lookAt)\n",
        "    # in terms of the camera's right and up vectors.\n",
        "    vec_from_lookat_to_proj_point = projected_point_3d_world - look_at\n",
        "\n",
        "    # Coordinates in the 2D image plane (in a coordinate system centered at lookAt)\n",
        "    # Ensure results are floats before scaling\n",
        "    proj_x_world = np.dot(vec_from_lookat_to_proj_point.astype(np.float64), right.astype(np.float64))\n",
        "    proj_y_world = np.dot(vec_from_lookat_to_proj_point.astype(np.float64), up.astype(np.float64))\n",
        "\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    # Now, map these 2D world coordinates (proj_x_world, proj_y_world) to pixel coordinates (proj_x, proj_y).\n",
        "    # This scaling and translation requires knowledge of the field of view or a mapping from world units to pixels.\n",
        "    # Without intrinsic parameters, this is still an estimation.\n",
        "    # Let's assume a simple linear mapping of a certain world region to the image plane.\n",
        "    # This is still a simplification.\n",
        "\n",
        "    # Given the difficulty of accurate perspective projection without intrinsics,\n",
        "    # let's try to make the simplified orthogonal projection slightly more intelligent\n",
        "    # by selecting the correct orthogonal view (XY, YZ, XZ) based on the camera's viewing direction,\n",
        "    # but still using a simplified mapping within the world bounds. This is a compromise.\n",
        "\n",
        "    # Revert to a view-type based projection for simplicity, but acknowledge the limitation.\n",
        "    # The metadata provides the *actual* camera pose, which is more complex than just 'front', 'side', 'top'.\n",
        "    # To truly use the metadata for projection, we need a proper perspective projection matrix.\n",
        "\n",
        "    # Let's assume for now that the first item in the metadata corresponds to a 'front' view,\n",
        "    # the second to a 'side', etc., and use the simplified view_type projection\n",
        "    # while acknowledging that the metadata *could* allow for better projection if we had intrinsics.\n",
        "\n",
        "    # Let's go back to the original simplified projection based on view type,\n",
        "    # but modify compute_visual_hull to *attempt* to infer view types from metadata\n",
        "    # or require a view_types list that matches the metadata order.\n",
        "    # The provided metadata structure (`position`, `lookAt`, `up`) doesn't directly give 'front', 'side', 'top' labels.\n",
        "    # We would need to analyze the camera vectors to classify the view, which is complex.\n",
        "\n",
        "    # Given the metadata structure, a better approach is to *try* to calculate the projection matrix\n",
        "    # and use it, even with assumptions.\n",
        "\n",
        "    # Let's restart the project_voxel_to_silhouette function with a better attempt at using metadata.\n",
        "    # We have the World to Camera (View) matrix. We need a Camera to Clip (Projection) matrix.\n",
        "    # Assuming a perspective projection with a standard field of view and aspect ratio is needed.\n",
        "    # Let's assume a simple perspective matrix for demonstration.\n",
        "\n",
        "    # Assumption: Simple perspective projection matrix (placeholder values)\n",
        "    # These values would ideally come from camera intrinsic calibration.\n",
        "    # fov_y = np.pi / 4 # 45 degrees\n",
        "    # aspect_ratio = img_width / img_height\n",
        "    # near = 0.1\n",
        "    # far = 100.0\n",
        "    # projection_matrix = np.zeros((4, 4))\n",
        "    # projection_matrix[0, 0] = 1.0 / (aspect_ratio * np.tan(fov_y / 2.0))\n",
        "    # projection_matrix[1, 1] = 1.0 / np.tan(fov_y / 2.0)\n",
        "    # projection_matrix[2, 2] = -(far + near) / (far - near)\n",
        "    # projection_matrix[2, 3] = -(2.0 * far * near) / (far - near)\n",
        "    # projection_matrix[3, 2] = -1.0\n",
        "\n",
        "    # Total transformation matrix (World to Clip)\n",
        "    # world_to_clip_matrix = np.dot(projection_matrix, view_matrix)\n",
        "\n",
        "    # Project the 3D point\n",
        "    # point_3d_clip = np.dot(world_to_clip_matrix, point_3d_world)\n",
        "\n",
        "    # Perform perspective division\n",
        "    # if point_3d_clip[3] == 0: # Avoid division by zero\n",
        "    #     return None, None\n",
        "    # point_3d_ndc = point_3d_clip[:3] / point_3d_clip[3] # Normalized Device Coordinates (-1 to 1)\n",
        "\n",
        "    # Map from NDC to pixel coordinates (0 to width/height)\n",
        "    # proj_x = int((point_3d_ndc[0] + 1.0) * 0.5 * img_width)\n",
        "    # proj_y = int((1.0 - point_3d_ndc[1]) * 0.5 * img_height) # Inverted Y axis for image coordinates\n",
        "\n",
        "    # Let's try a simpler approach using the camera orientation for alignment but keeping orthogonal scaling for now.\n",
        "    # This is still a significant simplification.\n",
        "\n",
        "    # Given the metadata, we can calculate the view direction.\n",
        "    view_direction = -forward # Camera looks along -forward\n",
        "\n",
        "    # Let's try to project based on the dominant axis of the view direction\n",
        "    abs_view_direction = np.abs(view_direction)\n",
        "    dominant_axis = np.argmax(abs_view_direction)\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    # Project based on the dominant viewing axis (simplified orthogonal)\n",
        "    # This is a heuristic and not a proper perspective projection.\n",
        "    # Ensure that the calculations result in floats before converting to int\n",
        "    if dominant_axis == 0: # Mostly looking along X axis (side view)\n",
        "        # Project onto YZ plane\n",
        "        proj_x = (voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width\n",
        "        proj_y = (volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height\n",
        "    elif dominant_axis == 1: # Mostly looking along Y axis (top/bottom view)\n",
        "        # Project onto XZ plane\n",
        "        proj_x = (voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width\n",
        "        proj_y = (volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height # Assuming Z maps to Y in image for top/bottom\n",
        "    elif dominant_axis == 2: # Mostly looking along Z axis (front/back view)\n",
        "        # Project onto XY plane\n",
        "        proj_x = (voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width\n",
        "        proj_y = (volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    # Ensure projected coordinates are within image bounds and convert to integers\n",
        "    # The error was here, implicitly converting floats to integers. Explicitly cast to int\n",
        "    # Added .0 to ensure float literals\n",
        "    proj_x = int(max(0.0, min(proj_x, img_width - 1.0)))\n",
        "    proj_y = int(max(0.0, min(proj_y, img_height - 1.0)))\n",
        "\n",
        "    return proj_y, proj_x # Return row, column\n",
        "\n",
        "\n",
        "# Modify compute_visual_hull to use the metadata\n",
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, metadata, show_previews=False):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes using camera metadata.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        metadata: The parsed dictionary from metadata.json.\n",
        "        show_previews: If True, display slices of the resulting voxel grid.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    print(\"Computing visual hull using camera metadata...\")\n",
        "    if not silhouettes or not metadata or 'frames' not in metadata:\n",
        "        print(\"No silhouettes or valid metadata provided for visual hull computation.\")\n",
        "        return np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8) # Return empty grid\n",
        "\n",
        "    # Ensure the number of silhouettes matches the number of camera frames in metadata\n",
        "    if len(silhouettes) != len(metadata['frames']):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of metadata frames ({len(metadata['frames'])}). Aborting.\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        # Add progress counter\n",
        "        total_voxels_to_check = grid_size * grid_size * grid_size\n",
        "        processed_voxels = 0\n",
        "        progress_interval = total_voxels_to_check // 10 # Report progress every 10%\n",
        "\n",
        "        for x in range(grid_size):\n",
        "            for y in range(grid_size):\n",
        "                for z in range(grid_size):\n",
        "                    # Add progress reporting\n",
        "                    processed_voxels += 1\n",
        "                    if processed_voxels % progress_interval == 0:\n",
        "                        print(f\"  Processed {processed_voxels}/{total_voxels_to_check} voxels ({processed_voxels/total_voxels_to_check:.0%})\")\n",
        "\n",
        "\n",
        "                    if voxel_grid[x, y, z] == 0:\n",
        "                        continue\n",
        "\n",
        "                    for i, silhouette in enumerate(silhouettes):\n",
        "                        camera_data = metadata['frames'][i]['camera_pose'] # Get camera data for this silhouette\n",
        "                        # Check for valid silhouette before projection\n",
        "                        if silhouette is None or silhouette.size == 0:\n",
        "                            print(f\"Warning: Skipping visual hull computation for invalid silhouette at index {i}.\")\n",
        "                            continue\n",
        "\n",
        "                        # Call project_voxel_to_silhouette with camera_data\n",
        "                        # The error was occurring in project_voxel_to_silhouette,\n",
        "                        # passing the correct data here is necessary but not the fix itself.\n",
        "                        proj_y, proj_x = project_voxel_to_silhouette(\n",
        "                            (x, y, z), silhouette.shape, camera_data, volume_bounds, grid_size\n",
        "                        )\n",
        "\n",
        "                        if proj_y is not None and proj_x is not None:\n",
        "                            # Assuming silhouette has object as 255 and background as 0\n",
        "                            # If projected point is in the black background (0), the voxel is outside the object\n",
        "                            # Ensure projected coordinates are within silhouette shape\n",
        "                            if 0 <= proj_y < silhouette.shape[0] and 0 <= proj_x < silhouette.shape[1]:\n",
        "                                if silhouette[proj_y, proj_x] == 0:\n",
        "                                    voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                                    break # No need to check other silhouettes for this voxel\n",
        "                            else:\n",
        "                                # If projection is outside image bounds, the voxel is definitely outside the silhouette\n",
        "                                voxel_grid[x, y, z] = 0\n",
        "                                break\n",
        "\n",
        "\n",
        "        print(\"Visual hull computation complete.\")\n",
        "\n",
        "        # --- Add check on the resulting voxel grid ---\n",
        "        num_occupied_voxels = np.sum(voxel_grid > 0)\n",
        "        total_voxels = grid_size * grid_size * grid_size\n",
        "\n",
        "        if num_occupied_voxels == 0:\n",
        "            print(\"Warning: The computed voxel grid is entirely empty. This may indicate issues with silhouette processing or view types/metadata.\")\n",
        "            # Optionally return None here if an empty grid should halt the pipeline\n",
        "            # return None\n",
        "        elif num_occupied_voxels == total_voxels:\n",
        "             print(\"Warning: The computed voxel grid is entirely filled. This likely indicates issues with silhouette processing or view types/metadata.\")\n",
        "             # Optionally return None here\n",
        "             # return None\n",
        "        else:\n",
        "            print(f\"Voxel grid contains {num_occupied_voxels} occupied voxels out of {total_voxels}.\")\n",
        "        # --- End of check ---\n",
        "\n",
        "\n",
        "        if show_previews and np.sum(voxel_grid > 0) > 0:\n",
        "            print(\"\\nDisplaying slices of the voxel grid:\")\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "            # Display a slice along the XZ plane (fixing Y)\n",
        "            y_slice = grid_size // 2\n",
        "            axes[0].imshow(voxel_grid[:, y_slice, :], cmap='gray', origin='lower')\n",
        "            axes[0].set_title(f'XZ slice (Y={y_slice})')\n",
        "            axes[0].set_xlabel('Z')\n",
        "            axes[0].set_ylabel('X')\n",
        "\n",
        "            # Display a slice along the YZ plane (fixing X)\n",
        "            x_slice = grid_size // 2\n",
        "            axes[1].imshow(voxel_grid[x_slice, :, :], cmap='gray', origin='lower')\n",
        "            axes[1].set_title(f'YZ slice (X={x_slice})')\n",
        "            axes[1].set_xlabel('Z')\n",
        "            axes[1].set_ylabel('Y')\n",
        "\n",
        "            # Display a slice along the XY plane (fixing Z)\n",
        "            z_slice = grid_size // 2\n",
        "            axes[2].imshow(voxel_grid[:, :, z_slice], cmap='gray', origin='lower')\n",
        "            axes[2].set_title(f'XY slice (Z={z_slice})')\n",
        "            axes[2].set_xlabel('Y')\n",
        "            axes[2].set_ylabel('X')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        elif show_previews and np.sum(voxel_grid > 0) == 0:\n",
        "            print(\"\\nVoxel grid is empty, cannot display slices.\")\n",
        "\n",
        "\n",
        "        return voxel_grid\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during visual hull computation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Modify run_reconstruction_pipeline to use load_images_from_directory and pass metadata\n",
        "def run_reconstruction_pipeline(extracted_files_path, metadata, grid_size=100, volume_bounds=None, marching_cubes_level=127, show_previews=True):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline using data from an extracted directory and metadata.\n",
        "\n",
        "    Args:\n",
        "        extracted_files_path: The path to the directory where files were extracted from the ZIP.\n",
        "        metadata: The parsed dictionary from metadata.json.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "                       If None, default bounds are used.\n",
        "        marching_cubes_level: The iso-surface value for Marching Cubes.\n",
        "        show_previews: If True, display previews of silhouettes and voxel grid slices.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Define default volume bounds if not provided\n",
        "    if volume_bounds is None:\n",
        "        volume_bounds = {\n",
        "            'x_min': -1.0, 'x_max': 1.0,\n",
        "            'y_min': -1.0, 'y_max': 1.0,\n",
        "            'z_min': -1.0, 'z_max': 1.0\n",
        "        }\n",
        "    print(f\"Using voxel grid size: {grid_size}x{grid_size}x{grid_size}\")\n",
        "    print(f\"Using volume bounds: {volume_bounds}\")\n",
        "    print(f\"Using Marching Cubes level: {marching_cubes_level}\")\n",
        "    print(f\"Show previews: {show_previews}\")\n",
        "\n",
        "    # Define the path to the silhouette images within the extracted directory\n",
        "    silhouettes_dir = os.path.join(extracted_files_path, 'silhouette') # Assuming 'silhouette' is the subfolder name\n",
        "\n",
        "    # Step 1: Load images from the extracted directory\n",
        "    print(\"\\nStep 1: Loading images from directory...\")\n",
        "    # Call the new load_images_from_directory function\n",
        "    images, image_filenames = load_images_from_directory(silhouettes_dir)\n",
        "\n",
        "    if not images:\n",
        "        print(\"Image loading failed or no images loaded from directory. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Match image filenames with metadata frames to get ordered camera data\n",
        "    # This assumes filenames in the directory match 'file_name' in metadata frames and are sorted correctly.\n",
        "    # A more robust approach would use the 'file_name' in metadata to load images in the correct order.\n",
        "    # Let's use the filenames from the directory and assume they are in the same order as metadata frames\n",
        "    # if sorted alphabetically, which is a common convention but might need confirmation.\n",
        "    # A safer approach is to iterate through metadata frames and load the corresponding file.\n",
        "\n",
        "    # Let's iterate through metadata frames to load images in the correct order\n",
        "    ordered_images = []\n",
        "    ordered_camera_data = []\n",
        "    print(\"\\nMatching metadata with image files...\")\n",
        "    for frame in metadata.get('frames', []):\n",
        "        file_name = frame.get('file_name')\n",
        "        if file_name:\n",
        "            file_path = os.path.join(silhouettes_dir, file_name)\n",
        "            if os.path.exists(file_path):\n",
        "                 # Read image in grayscale\n",
        "                img_grayscale = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img_grayscale is not None:\n",
        "                    ordered_images.append(img_grayscale)\n",
        "                    ordered_camera_data.append(frame.get('camera_pose'))\n",
        "                    print(f\"Matched and loaded image for {file_name}.\")\n",
        "                else:\n",
        "                     print(f\"Warning: Could not load image file based on metadata: {file_name}\")\n",
        "            else:\n",
        "                 print(f\"Warning: Image file not found based on metadata: {file_name}\")\n",
        "        else:\n",
        "            print(\"Warning: 'file_name' missing in metadata frame.\")\n",
        "\n",
        "    if len(ordered_images) == 0:\n",
        "        print(\"No images loaded after matching with metadata. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Successfully loaded {len(ordered_images)} images matching metadata.\")\n",
        "\n",
        "\n",
        "    # Step 2: Process silhouettes (already grayscale and should be silhouettes from the pipeline)\n",
        "    # Since the input is expected to be silhouetted images already, this step might be simplified\n",
        "    # or the process_silhouettes function could be adapted to verify they are binary.\n",
        "    # For now, let's keep the thresholding as a verification/standardization step.\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    # Pass ordered_images to process_silhouettes\n",
        "    silhouettes = process_silhouettes(ordered_images, show_previews=show_previews)\n",
        "\n",
        "    if silhouettes is None or not silhouettes:\n",
        "        print(\"Silhouette processing failed or no silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Ensure the number of processed silhouettes matches the number of loaded camera data\n",
        "    if len(silhouettes) != len(ordered_camera_data):\n",
        "         print(f\"Error: Number of processed silhouettes ({len(silhouettes)}) does not match number of loaded camera data ({len(ordered_camera_data)}). Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "\n",
        "    # Step 3: Compute visual hull using metadata\n",
        "    print(\"\\nStep 3: Computing visual hull using metadata...\")\n",
        "    # Pass ordered_camera_data to compute_visual_hull\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, {'frames': [{'camera_pose': cd} for cd in ordered_camera_data]}, show_previews=show_previews) # Pass simplified metadata structure\n",
        "\n",
        "    # Check if the visual hull computation returned a valid grid\n",
        "    if voxel_grid is None or voxel_grid.shape != (grid_size, grid_size, grid_size):\n",
        "         print(\"Visual hull computation failed or returned an invalid grid. Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    # Pass volume_bounds and grid_size to generate_mesh\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid, volume_bounds, grid_size, level=marching_cubes_level)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'extracted_files_path' and 'uploaded_metadata' are populated\n",
        "# from the execution of the zip extraction cell (fd68770c).\n",
        "\n",
        "# Check if extracted_files_path in locals() and extracted_files_path is not None\n",
        "# and uploaded_metadata in locals() and uploaded_metadata is not None before calling the pipeline\n",
        "if 'extracted_files_path' in locals() and extracted_files_path and 'uploaded_metadata' in locals() and uploaded_metadata:\n",
        "    print(\"\\nRunning pipeline with extracted data and metadata.\")\n",
        "\n",
        "    # Call the main pipeline function with configurable options\n",
        "    run_reconstruction_pipeline(\n",
        "        extracted_files_path=extracted_files_path,\n",
        "        metadata=uploaded_metadata,\n",
        "        grid_size=150,  # Example: use a medium grid size\n",
        "        volume_bounds={'x_min': -1.5, 'x_max': 1.5, 'y_min': -1.5, 'y_max': 1.5, 'z_min': -1.5, 'z_max': 1.5}, # Example: adjust bounds\n",
        "        marching_cubes_level=127, # Example: use level 127\n",
        "        show_previews=True # Keep previews enabled\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nExtracted files path or uploaded metadata is not defined or is empty.\")\n",
        "    print(\"Please execute the ZIP extraction cell (fd68770c) first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627a542a"
      },
      "source": [
        "## Processar silhuetas e configurar o volume\n",
        "\n",
        "### Subtask:\n",
        "Refinar a extração de silhuetas para múltiplas imagens e definir os parâmetros para a grade de voxels (volume 3D) onde a reconstrução ocorrerá.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf24e76"
      },
      "source": [
        "**Reasoning**:\n",
        "Process each uploaded image to extract silhouettes and define the voxel grid parameters for 3D reconstruction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e727840"
      },
      "source": [
        "silhouettes = []\n",
        "if uploaded_images:\n",
        "    for file_name, content in uploaded_images.items():\n",
        "        # Convert byte content to numpy array\n",
        "        np_arr = np.frombuffer(content, np.uint8)\n",
        "        # Read image in grayscale\n",
        "        img_grayscale = cv2.imdecode(np_arr, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply binary inverse thresholding\n",
        "        _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "        silhouettes.append(silhouette)\n",
        "        print(f\"Processed {file_name} and extracted silhouette.\")\n",
        "\n",
        "# Define voxel grid parameters\n",
        "grid_size = 100\n",
        "# Assuming a cubic volume centered at origin, adjust bounds based on expected object size\n",
        "# These bounds will need to be refined based on camera parameters if available\n",
        "volume_bounds = {\n",
        "    'x_min': -1.0, 'x_max': 1.0,\n",
        "    'y_min': -1.0, 'y_max': 1.0,\n",
        "    'z_min': -1.0, 'z_max': 1.0\n",
        "}\n",
        "\n",
        "# Initialize the voxel grid (representing the 3D space)\n",
        "# A value of 255 can indicate occupied space, 0 can indicate empty space\n",
        "voxel_grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
        "\n",
        "print(f\"\\nDefined voxel grid with size {grid_size}x{grid_size}x{grid_size} and bounds:\")\n",
        "print(volume_bounds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4104ff41"
      },
      "source": [
        "## Implementar o algoritmo visual hull\n",
        "\n",
        "### Subtask:\n",
        "Desenvolver o código para projetar as silhuetas no volume 3D e identificar os voxels que pertencem ao objeto.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f727e1a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the visual hull algorithm by iterating through each voxel and projecting it onto each silhouette to determine if it's inside the silhouette.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "253c7051"
      },
      "source": [
        "# Assume simple orthogonal projection for front, side, and top views\n",
        "# This is a simplified assumption and would require actual camera parameters for accuracy\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \"\"\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\"\"\"\n",
        "    # Convert voxel grid coordinates (integers) to world coordinates (floats)\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    # Project based on view type (simplified orthogonal projection)\n",
        "    if view_type == 'front': # Projecting onto the YZ plane\n",
        "        # Map world coordinates to image pixel coordinates\n",
        "        # Assuming Y maps to image row (inverted) and Z maps to image column\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side': # Projecting onto the XZ plane\n",
        "        # Assuming Y maps to image row (inverted) and X maps to image column\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top': # Projecting onto the XY plane\n",
        "        # Assuming X maps to image column and Z maps to image row (inverted)\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        # Handle other view types or raise an error\n",
        "        return None, None # Or raise an exception\n",
        "\n",
        "    # Ensure projected coordinates are within image bounds\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x # Return row, column\n",
        "\n",
        "# Assuming the order of silhouettes corresponds to a known view type\n",
        "# This is a simplification and in a real scenario, camera poses would be needed\n",
        "view_types = ['front', 'side', 'top', 'side', 'front', 'side', 'front', 'side', 'top'] # Example view types matching the number of uploaded images\n",
        "\n",
        "# Initialize voxel grid as potentially occupied\n",
        "voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "# Iterate through each voxel\n",
        "for x in range(grid_size):\n",
        "    for y in range(grid_size):\n",
        "        for z in range(grid_size):\n",
        "            # If a voxel has already been marked as empty, skip it\n",
        "            if voxel_grid[x, y, z] == 0:\n",
        "                continue\n",
        "\n",
        "            # Iterate through each silhouette\n",
        "            for i, silhouette in enumerate(silhouettes):\n",
        "                view_type = view_types[i] # Get the corresponding view type\n",
        "                proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                # Check if projection is valid and if the projected point is outside the silhouette\n",
        "                if proj_y is not None and proj_x is not None:\n",
        "                    if silhouette[proj_y, proj_x] == 0: # Assuming silhouette has object as 255 and background as 0\n",
        "                        voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                        break # No need to check other silhouettes for this voxel\n",
        "\n",
        "print(\"Visual hull computation complete.\")\n",
        "print(f\"Voxel grid shape: {voxel_grid.shape}\")\n",
        "print(f\"Number of occupied voxels: {np.sum(voxel_grid > 0)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cf3d10b"
      },
      "source": [
        "**Reasoning**:\n",
        "The visual hull has been computed by projecting voxels onto the silhouettes. The next step is to apply the Marching Cubes algorithm to the resulting voxel grid to generate a mesh representation of the 3D object and then save the mesh.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40c4140"
      },
      "source": [
        "from skimage import measure\n",
        "import trimesh\n",
        "\n",
        "# Use Marching Cubes to generate a mesh from the voxel grid\n",
        "# The level parameter determines the iso-surface value; 127 is a reasonable midpoint\n",
        "# between 0 (empty) and 255 (occupied)\n",
        "vertices, faces, normals, values = measure.marching_cubes(voxel_grid, level=127)\n",
        "\n",
        "# Create a trimesh object from the generated vertices and faces\n",
        "mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "\n",
        "# Export the mesh as a GLB file\n",
        "output_filename = 'reconstructed_model.glb'\n",
        "mesh.export(output_filename)\n",
        "\n",
        "print(f\"3D model reconstructed and saved as {output_filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84bef96b"
      },
      "source": [
        "## Visualizar e exportar o modelo 3d\n",
        "\n",
        "### Subtask:\n",
        "Adicionar código para visualizar a malha 3D gerada (usando `matplotlib` ou `trimesh`) e implementar a exportação da malha para o formato `.glb` usando a biblioteca `trimesh`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82159cf7"
      },
      "source": [
        "**Reasoning**:\n",
        "Check if the mesh object exists and if trimesh is available, then use trimesh to visualize the mesh and confirm the GLB export.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21fa2304"
      },
      "source": [
        "if 'mesh' in locals() and mesh is not None:\n",
        "    print(\"Mesh object exists. Attempting visualization and verifying export.\")\n",
        "\n",
        "    # In a Colab environment, mesh.show() might not work directly.\n",
        "    # A common approach is to save the mesh and then use a viewer.\n",
        "    # Since we already exported to GLB in the previous step, we can confirm that.\n",
        "\n",
        "    # Verify if the GLB file was created\n",
        "    import os\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    if os.path.exists(output_filename):\n",
        "        print(f\"Successfully exported mesh to {output_filename}\")\n",
        "    else:\n",
        "        print(f\"Error: {output_filename} was not created.\")\n",
        "\n",
        "    # For visualization within Colab, we can't use mesh.show() directly.\n",
        "    # One way is to use an external library or save and re-load with a Colab-compatible viewer.\n",
        "    # As per instructions, we focus on confirming export and mentioning visualization.\n",
        "    print(\"\\nVisualization of the 3D mesh in this environment typically requires saving the model and using a compatible viewer or library.\")\n",
        "    print(f\"The mesh was exported to '{output_filename}'. You can download this file and view it in a 3D model viewer.\")\n",
        "\n",
        "else:\n",
        "    print(\"Mesh object does not exist. Please run the previous steps to generate the mesh.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f5b7042"
      },
      "source": [
        "## Refinar e testar\n",
        "\n",
        "### Subtask:\n",
        "Adicionar etapas para refinar a malha se necessário (remoção de ruído, suavização - opcional) e testar o pipeline completo com diferentes conjuntos de silhuetas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d77c37"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the exported GLB file, apply optional refinement techniques, and export the refined mesh.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6abae061"
      },
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/sample_data/'\n",
        "\n",
        "# List all files in the folder\n",
        "files_in_folder = os.listdir(folder_path)\n",
        "\n",
        "print(f\"Arquivos na pasta '{folder_path}':\")\n",
        "for file_name in files_in_folder:\n",
        "    print(file_name)\n",
        "\n",
        "# Delete each file in the folder\n",
        "print(\"\\nExcluindo arquivos...\")\n",
        "for file_name in files_in_folder:\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "            print(f\"Excluído: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao excluir {file_name}: {e}\")\n",
        "\n",
        "print(\"\\nExclusão concluída.\")\n",
        "\n",
        "# Verify if the folder is empty\n",
        "files_after_deletion = os.listdir(folder_path)\n",
        "if not files_after_deletion:\n",
        "    print(\"A pasta sample_data está vazia.\")\n",
        "else:\n",
        "    print(\"Arquivos restantes na pasta sample_data:\")\n",
        "    for file_name in files_after_deletion:\n",
        "        print(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eaf1a74"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that `reconstructed_mesh` is a `Scene` object, not a `Trimesh` object, and `Scene` objects do not have a `split` method. I need to extract the mesh from the scene before attempting to split it into components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_eYA5kytIr5"
      },
      "source": [
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "\n",
        "# Load the exported GLB file\n",
        "output_filename = 'reconstructed_model.glb'\n",
        "if os.path.exists(output_filename):\n",
        "    # Load the scene\n",
        "    scene = trimesh.load(output_filename)\n",
        "    print(f\"Loaded {output_filename} as a Scene for refinement.\")\n",
        "\n",
        "    # Extract the mesh from the scene. Assuming the first geometry is the mesh.\n",
        "    # In a more complex scene, you might need a different approach to select the correct mesh.\n",
        "    if isinstance(scene, trimesh.Scene):\n",
        "        # Try to get the main mesh from the scene's geometry\n",
        "        mesh_list = list(scene.geometry.values())\n",
        "        if mesh_list:\n",
        "            reconstructed_mesh = mesh_list[0]\n",
        "            print(\"Extracted mesh from the loaded scene.\")\n",
        "        else:\n",
        "            reconstructed_mesh = None\n",
        "            print(\"No geometry found in the loaded scene.\")\n",
        "    else:\n",
        "        # If it's not a scene, assume it's already a mesh (though the error suggests otherwise)\n",
        "        reconstructed_mesh = scene\n",
        "        print(\"Loaded object is not a Scene, assuming it is a mesh.\")\n",
        "\n",
        "\n",
        "    if reconstructed_mesh is not None and isinstance(reconstructed_mesh, trimesh.Trimesh):\n",
        "        # --- Optional Refinement Steps ---\n",
        "\n",
        "        # 1. Remove smallest disconnected components (noise)\n",
        "        # Calculate the connected components\n",
        "        components = reconstructed_mesh.split(only_watertight=False)\n",
        "\n",
        "        if components:\n",
        "            # Sort components by number of faces (or vertices) and keep the largest\n",
        "            components.sort(key=lambda m: len(m.faces), reverse=True)\n",
        "            # Keep only the largest component(s) - adjust the number [:] as needed\n",
        "            reconstructed_mesh = components[0]\n",
        "            print(f\"Removed {len(components) - 1} smaller disconnected components.\")\n",
        "        else:\n",
        "            print(\"No disconnected components found or mesh is empty after loading.\")\n",
        "\n",
        "\n",
        "        # 2. Apply Laplacian smoothing\n",
        "        # Be cautious with iterations and lambda - too many can distort the shape\n",
        "        # reconstructed_mesh = trimesh.smoothing.filter_laplacian(reconstructed_mesh, iterations=5, lamb=0.1)\n",
        "        # print(\"Applied Laplacian smoothing.\")\n",
        "\n",
        "        # --- End of Optional Refinement Steps ---\n",
        "\n",
        "\n",
        "        # Export the refined mesh to a new GLB file\n",
        "        refined_output_filename = 'reconstructed_model_refined.glb'\n",
        "        reconstructed_mesh.export(refined_output_filename)\n",
        "        print(f\"Refined mesh saved as {refined_output_filename}\")\n",
        "    elif reconstructed_mesh is None:\n",
        "         print(\"No valid mesh object available for refinement.\")\n",
        "    else:\n",
        "         print(f\"Loaded object is of type {type(reconstructed_mesh)}, which is not a trimesh.Trimesh object. Cannot perform refinement.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(f\"Error: {output_filename} not found. Cannot perform refinement.\")\n",
        "\n",
        "# Note on testing with different silhouette sets:\n",
        "# To test the complete pipeline with different sets of silhouettes,\n",
        "# you would need to repeat the entire notebook execution starting from the\n",
        "# image upload step (Step 1: Preparar o ambiente e carregar dados) with\n",
        "# each new set of images. After execution, you would download and visually\n",
        "# inspect the 'reconstructed_model.glb' (or 'reconstructed_model_refined.glb')\n",
        "# file using an external 3D viewer for each test case."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd1bdb4"
      },
      "source": [
        "# Task\n",
        "Refactor the existing code in the notebook to create a framework similar to StudioNERF, allowing users to input images and automatically generate a 3D model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a83648c6"
      },
      "source": [
        "## Estruturar o código existente\n",
        "\n",
        "### Subtask:\n",
        "Organize the existing code into well-defined Python functions for image loading, silhouette processing, visual hull computation, marching cubes mesh generation, and GLB export.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cc4942a"
      },
      "source": [
        "**Reasoning**:\n",
        "Organize the existing code into Python functions for image loading, silhouette processing, visual hull computation, marching cubes mesh generation, and GLB export as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16888316"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure\n",
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def load_images(uploaded_files):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from uploaded files.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "\n",
        "    Returns:\n",
        "        A list of loaded grayscale images.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    if uploaded_files:\n",
        "        for file_name, content in uploaded_files.items():\n",
        "            np_arr = np.frombuffer(content, np.uint8)\n",
        "            img_grayscale = cv2.imdecode(np_arr, cv2.IMREAD_GRAYSCALE)\n",
        "            images.append(img_grayscale)\n",
        "            print(f\"Loaded {file_name}.\")\n",
        "    else:\n",
        "        print(\"No files uploaded.\")\n",
        "    return images\n",
        "\n",
        "\n",
        "def process_silhouettes(images):\n",
        "    \"\"\"\n",
        "    Extracts silhouettes from a list of grayscale images.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks).\n",
        "    \"\"\"\n",
        "    silhouettes = []\n",
        "    for img_grayscale in images:\n",
        "        _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "        silhouettes.append(silhouette)\n",
        "    print(f\"Processed {len(silhouettes)} images and extracted silhouettes.\")\n",
        "    return silhouettes\n",
        "\n",
        "\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \"\"\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\"\"\"\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    if view_type == 'front':\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x\n",
        "\n",
        "\n",
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid.\n",
        "    \"\"\"\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(\"Warning: Number of silhouettes and view types do not match.\")\n",
        "        return voxel_grid\n",
        "\n",
        "    for x in range(grid_size):\n",
        "        for y in range(grid_size):\n",
        "            for z in range(grid_size):\n",
        "                if voxel_grid[x, y, z] == 0:\n",
        "                    continue\n",
        "\n",
        "                for i, silhouette in enumerate(silhouettes):\n",
        "                    view_type = view_types[i]\n",
        "                    proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                    if proj_y is not None and proj_x is not None:\n",
        "                        if silhouette[proj_y, proj_x] == 0:\n",
        "                            voxel_grid[x, y, z] = 0\n",
        "                            break\n",
        "\n",
        "    print(\"Visual hull computation complete.\")\n",
        "    return voxel_grid\n",
        "\n",
        "\n",
        "def generate_mesh(voxel_grid, level=127):\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid.\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(\"Mesh generated using Marching Cubes.\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(f\"Error during mesh generation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def export_mesh(mesh, output_filename):\n",
        "    \"\"\"\n",
        "    Exports a trimesh object to a GLB file.\n",
        "\n",
        "    Args:\n",
        "        mesh: A trimesh object.\n",
        "        output_filename: The name of the output GLB file.\n",
        "    \"\"\"\n",
        "    if mesh is not None:\n",
        "        try:\n",
        "            mesh.export(output_filename)\n",
        "            print(f\"Mesh exported to {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during mesh export: {e}\")\n",
        "    else:\n",
        "        print(\"No mesh to export.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33f09064"
      },
      "source": [
        "## Desenvolver uma interface de entrada\n",
        "\n",
        "### Subtask:\n",
        "Create a more user-friendly way for the user to provide images, possibly using `ipywidgets` for a Colab environment, or by outlining a structure for a future web application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b0e3271"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries for file uploading and potentially ipywidgets for a more interactive experience, and then prompt the user to upload multiple images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37f75d5d"
      },
      "source": [
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def upload_silhouettes_widget():\n",
        "    \"\"\"\n",
        "    Creates a file upload widget for multiple silhouette images.\n",
        "    \"\"\"\n",
        "    print(\"Please upload the silhouette images for 3D reconstruction.\")\n",
        "    uploader = files.upload()\n",
        "    return uploader\n",
        "\n",
        "# Call the upload function\n",
        "uploaded_files = upload_silhouettes_widget()\n",
        "\n",
        "# Store uploaded files (already done by files.upload() but confirming structure)\n",
        "# uploaded_files is a dictionary {filename: content}\n",
        "\n",
        "# Provide feedback to the user\n",
        "if uploaded_files:\n",
        "    print(\"\\nSuccessfully uploaded the following files:\")\n",
        "    for file_name in uploaded_files.keys():\n",
        "        print(f\"- {file_name}\")\n",
        "else:\n",
        "    print(\"\\nNo files were uploaded.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37586a1a"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline how image input would be handled in a future web application.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62dfe97f"
      },
      "source": [
        "# Outline for future web application image input:\n",
        "\n",
        "# In a web application context (e.g., using React, HTML, JavaScript),\n",
        "# image input would typically be handled using standard web technologies.\n",
        "\n",
        "# 1. HTML:\n",
        "#    An HTML form with an input element of type \"file\" and the \"multiple\" attribute\n",
        "#    would allow users to select multiple image files from their local machine.\n",
        "#    A drag-and-drop area could also be implemented using JavaScript event listeners\n",
        "#    (dragover, drop).\n",
        "\n",
        "#    Example HTML:\n",
        "#    <input type=\"file\" id=\"silhouetteFileInput\" accept=\"image/*\" multiple>\n",
        "#    <div id=\"dragDropArea\">Drag and drop images here</div>\n",
        "\n",
        "# 2. JavaScript:\n",
        "#    JavaScript would be used to handle the file input change event or the drag-and-drop\n",
        "#    drop event. The selected files would be accessed via the `event.target.files`\n",
        "#    (for input) or `event.dataTransfer.files` (for drag-and-drop).\n",
        "\n",
        "#    The file contents can then be read using the `FileReader` API.\n",
        "\n",
        "#    Example JavaScript (for file input):\n",
        "#    document.getElementById('silhouetteFileInput').addEventListener('change', function(event) {\n",
        "#        const files = event.target.files;\n",
        "#        for (const file of files) {\n",
        "#            const reader = new FileReader();\n",
        "#            reader.onload = (e) => {\n",
        "#                // e.target.result contains the file content (e.g., as a Data URL or ArrayBuffer)\n",
        "#                // This content would then be sent to the backend or processed client-side\n",
        "#                console.log(`File ${file.name} read.`);\n",
        "#                // Process the image data (e.g., send to a server for processing)\n",
        "#            };\n",
        "#            reader.readAsDataURL(file); // Or reader.readAsArrayBuffer(file)\n",
        "#        }\n",
        "#    });\n",
        "\n",
        "# 3. Backend (Optional but Recommended for Heavy Processing):\n",
        "#    For computationally intensive tasks like 3D reconstruction, the image data\n",
        "#    read by JavaScript would typically be sent to a backend server (e.g., using Python\n",
        "#    with Flask/Django, Node.js, etc.) via an API endpoint.\n",
        "#    The backend would receive the image data, perform the silhouette extraction,\n",
        "#    visual hull computation, and mesh generation using libraries like OpenCV, scikit-image,\n",
        "#    and trimesh (as demonstrated in this notebook).\n",
        "#    The resulting 3D model (e.g., a GLB file) would then be sent back to the frontend\n",
        "#    for visualization.\n",
        "\n",
        "# This approach separates the user interface (frontend) from the heavy processing (backend),\n",
        "# providing a responsive user experience."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aa5373a"
      },
      "source": [
        "## Automate the pipeline\n",
        "\n",
        "### Subtask:\n",
        "Create a main function that orchestrates the execution of the functions from the previous steps in sequence: loading images, processing silhouettes, computing the visual hull, generating the mesh, and exporting the GLB file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756df65a"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a main function `run_reconstruction_pipeline` that orchestrates the steps of the 3D reconstruction process using the functions defined previously. This function will take the uploaded files and view types as input, process them through the pipeline, and export the final mesh.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40440407"
      },
      "source": [
        "def run_reconstruction_pipeline(uploaded_files, view_types):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if not images:\n",
        "        print(\"No images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    silhouettes = process_silhouettes(images)\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Define parameters for the visual hull\n",
        "    grid_size = 100\n",
        "    volume_bounds = {\n",
        "        'x_min': -1.0, 'x_max': 1.0,\n",
        "        'y_min': -1.0, 'y_max': 1.0,\n",
        "        'z_min': -1.0, 'z_max': 1.0\n",
        "    }\n",
        "    print(f\"\\nDefined voxel grid parameters: size={grid_size}, bounds={volume_bounds}\")\n",
        "\n",
        "    # Step 3: Compute visual hull\n",
        "    print(\"\\nStep 3: Computing visual hull...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types)\n",
        "    if voxel_grid is None or np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation failed or resulted in an empty grid. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'uploaded_files' is already populated from the previous upload step\n",
        "# and 'view_types' is defined to match the order and type of uploaded images.\n",
        "# This is a placeholder list; replace with actual view types based on your uploaded images.\n",
        "# Example: If you uploaded front, side, top, and another side view:\n",
        "# example_view_types = ['front', 'side', 'top', 'side']\n",
        "\n",
        "# For the images uploaded in the history: 9 images. Let's assume an example sequence of view types.\n",
        "# The actual view types would depend on how the images were captured.\n",
        "# This example assumes a sequence of views around the object.\n",
        "example_view_types = ['view1', 'view2', 'view3', 'view4', 'view5', 'view6', 'view7', 'view8', 'view9'] # Replace with actual view types\n",
        "\n",
        "# Call the main pipeline function\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "313bdfac"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed because the number of silhouettes did not match the number of view types provided. I need to update the `example_view_types` list to match the actual number of uploaded images (15, as indicated by the output) and provide more meaningful view types if possible, although the current projection model is a simplification. I will also add a check for the number of silhouettes and view types before calling `compute_visual_hull` within the main function for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b87ddd"
      },
      "source": [
        "# Update the example_view_types to match the number of uploaded images (15)\n",
        "# This is still a placeholder; actual view types depend on the image capture.\n",
        "example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "print(f\"\\nUpdated example_view_types to match {len(example_view_types)} uploaded images.\")\n",
        "print(example_view_types)\n",
        "\n",
        "\n",
        "def run_reconstruction_pipeline(uploaded_files, view_types):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if not images:\n",
        "        print(\"No images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    silhouettes = process_silhouettes(images)\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Define parameters for the visual hull\n",
        "    grid_size = 100\n",
        "    volume_bounds = {\n",
        "        'x_min': -1.0, 'x_max': 1.0,\n",
        "        'y_min': -1.0, 'y_max': 1.0,\n",
        "        'z_min': -1.0, 'z_max': 1.0\n",
        "    }\n",
        "    print(f\"\\nDefined voxel grid parameters: size={grid_size}, bounds={volume_bounds}\")\n",
        "\n",
        "    # Check if the number of silhouettes matches the number of view types\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}). Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Compute visual hull\n",
        "    print(\"\\nStep 3: Computing visual hull...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types)\n",
        "    # Check if the visual hull computation returned a valid grid\n",
        "    if voxel_grid is None or voxel_grid.shape != (grid_size, grid_size, grid_size):\n",
        "         print(\"Visual hull computation failed or returned an invalid grid. Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    # Pass the voxel grid directly to generate_mesh\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "# Call the main pipeline function with the corrected view types\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07fbb87c"
      },
      "source": [
        "**Reasoning**:\n",
        "The mesh generation failed with the error \"Surface level must be within volume data range\". This indicates that the default `level=127` for `measure.marching_cubes` is not appropriate for the calculated `voxel_grid`. The `voxel_grid` currently contains values of either 0 (empty) or 255 (occupied). The marching cubes algorithm is looking for an isosurface at level 127, but all values are at the extremes. I need to change the `level` parameter in the `generate_mesh` function to either a value between 0 and 255 that represents the boundary, or more appropriately, since the grid is binary (0 or 255), choose a level that explicitly separates these two values. A level of 0 or slightly above (e.g., 0.5) or a level of 255 or slightly below (e.g., 254.5) should work. Let's try a level of 0.5 to consider everything above 0 as part of the surface. I will modify the `generate_mesh` function to use `level=0.5`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8efb1190"
      },
      "source": [
        "**Reasoning**:\n",
        "The Marching Cubes algorithm still fails with the same error, even with `level=0.5`. This is likely because `skimage.measure.marching_cubes` expects the `level` to be within the range of the *values* in the input volume. Since the `voxel_grid` currently only contains 0 and 255, a level of 0.5 is still outside this range. I need to either adjust the values in the `voxel_grid` or choose a level that is exactly 0 or 255. Given that 0 represents empty space and 255 represents occupied space, the isosurface should lie between these two values. Let's try explicitly using a level of 127 again, but ensure the voxel grid is treated as containing continuous values between 0 and 255, which is the default assumption for `marching_cubes` when the data type is not float. Alternatively, a robust approach for binary data is to use `level=0`. Let's try `level=0`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a42a573"
      },
      "source": [
        "# Modify the generate_mesh function again to use level=0 for marching cubes\n",
        "def generate_mesh(voxel_grid, level=0): # Changed default level to 0\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid.\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # No need to convert to float if level is 0\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(f\"Mesh generated using Marching Cubes with level={level}.\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(f\"Error during mesh generation with level={level}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Call the main pipeline function again with the corrected generate_mesh\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf11e50"
      },
      "source": [
        "**Reasoning**:\n",
        "Marching cubes is still failing with `level=0`. This is unexpected given the binary nature of the data. It might be an issue with how `skimage.measure.marching_cubes` interprets the levels with `uint8` data. A workaround for binary data is to convert the data type to boolean or a floating-point type and then use a level of 0.5 or 0. Let's try converting the `voxel_grid` to boolean where 255 is True and 0 is False, and then use `level=0` or `level=0.5` which should work for boolean data. According to scikit-image documentation, for binary data (True/False or 1/0), `level` should be between 0 and 1. A common choice is 0.5 to get the boundary between 0 and 1. I will convert to boolean and use `level=0.5`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306a17b4"
      },
      "source": [
        "# Modify the generate_mesh function again to convert voxel_grid to boolean and use level=0.5\n",
        "def generate_mesh(voxel_grid, level=0.5): # Keep level=0.5 for boolean data\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid (uint8, 0 or 255).\n",
        "        level: The iso-surface value for Marching Cubes (should be between 0 and 1 for boolean data).\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert the voxel grid to boolean: True where voxel_grid > 0 (i.e., 255), False where voxel_grid == 0\n",
        "        voxel_grid_bool = voxel_grid > 0\n",
        "        # Use marching_cubes with the boolean grid and level=0.5\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid_bool, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(f\"Mesh generated using Marching Cubes with level={level} on boolean data.\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(f\"Error during mesh generation with level={level} on boolean data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Call the main pipeline function again with the corrected generate_mesh\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bd63951"
      },
      "source": [
        "**Reasoning**:\n",
        "Marching cubes is still failing with the same error even after converting to boolean. This is very unusual and suggests a deeper issue with how `marching_cubes` is handling the input data in this environment, or potentially an edge case with the specific binary data produced by the visual hull. As a last attempt with `marching_cubes`, I will try converting the voxel grid to float and explicitly setting the level to 127 again, as this is the midpoint between 0 and 255 and should theoretically work for `uint8` data treated as float. If this still fails, it indicates a persistent issue with `marching_cubes` or the data that is difficult to debug without further information or a different environment. If it fails again, I will conclude the subtask as failed since mesh generation is a core requirement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e1f50e6"
      },
      "source": [
        "# Modify the generate_mesh function to convert to float and use level=127\n",
        "def generate_mesh(voxel_grid, level=127): # Revert level to 127, convert to float\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid (uint8, 0 or 255).\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert the voxel grid to float to ensure level works as expected\n",
        "        voxel_grid_float = voxel_grid.astype(np.float64)\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid_float, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(f\"Mesh generated using Marching Cubes with level={level} on float data.\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(f\"Error during mesh generation with level={level} on float data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Call the main pipeline function again\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18b2cf70"
      },
      "source": [
        "## Adicionar feedback visual (opcional mas recomendado)\n",
        "\n",
        "### Subtask:\n",
        "Although direct interactive 3D visualization within Google Colab notebooks can be challenging, add steps to provide visual feedback on the input silhouettes and the resulting voxel grid to help users understand the process and diagnose potential issues.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e86023f"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the first instruction by modifying the `process_silhouettes` function to display grayscale and silhouette images if `show_previews` is True.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fcbceb6"
      },
      "source": [
        "def process_silhouettes(images, show_previews=False):\n",
        "    \"\"\"\n",
        "    Extracts silhouettes from a list of grayscale images with error handling,\n",
        "    applies basic morphological operations for cleaning, and optionally displays previews.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "        show_previews: If True, display the original grayscale image and the extracted silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks), or None if an error occurs.\n",
        "    \"\"\"\n",
        "    silhouettes = []\n",
        "    print(\"Processing silhouettes...\")\n",
        "    if not images:\n",
        "        print(\"No images provided for silhouette processing.\")\n",
        "        return silhouettes\n",
        "    try:\n",
        "        # Define kernel for morphological operations\n",
        "        # A small kernel is usually sufficient for minor cleaning\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "        for i, img_grayscale in enumerate(images):\n",
        "            # Ensure image is valid before processing\n",
        "            if img_grayscale is None or img_grayscale.size == 0:\n",
        "                print(f\"Warning: Skipping processing for invalid image at index {i}.\")\n",
        "                continue\n",
        "\n",
        "            # Apply binary inverse thresholding\n",
        "            _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "            # --- Apply morphological operations for cleaning ---\n",
        "            # Optional: Erosion followed by Dilation (Opening) to remove small objects/noise\n",
        "            # Optional: Dilation followed by Erosion (Closing) to close small holes\n",
        "            # The parameters (iterations) might need tuning based on the noise level\n",
        "            silhouette = cv2.erode(silhouette, kernel, iterations=1)\n",
        "            silhouette = cv2.dilate(silhouette, kernel, iterations=1)\n",
        "            # Optional: Close small holes\n",
        "            # silhouette = cv2.dilate(silhouette, kernel, iterations=1)\n",
        "            # silhouette = cv2.erode(silhouette, kernel, iterations=1)\n",
        "            # --- End of morphological operations ---\n",
        "\n",
        "\n",
        "            silhouettes.append(silhouette)\n",
        "            if show_previews:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.title(f'Original Image {i+1} (Grayscale)')\n",
        "                plt.imshow(img_grayscale, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.title(f'Silhouette {i+1} Extracted and Cleaned')\n",
        "                plt.imshow(silhouette, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "        print(f\"Finished processing {len(silhouettes)} images and extracted silhouettes.\")\n",
        "        return silhouettes\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during silhouette processing: {e}\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7328a418"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the second instruction by adding code to the `compute_visual_hull` function to display slices of the voxel grid after computation if `show_previews` is True.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0f784cf"
      },
      "source": [
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=False):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes with error handling,\n",
        "    adds a check on the resulting voxel grid, and optionally displays slices.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "        show_previews: If True, display slices of the resulting voxel grid.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    print(\"Computing visual hull...\")\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes provided for visual hull computation.\")\n",
        "        return np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8) # Return empty grid\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}).\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        for x in range(grid_size):\n",
        "            for y in range(grid_size):\n",
        "                for z in range(grid_size):\n",
        "                    if voxel_grid[x, y, z] == 0:\n",
        "                        continue\n",
        "\n",
        "                    for i, silhouette in enumerate(silhouettes):\n",
        "                        view_type = view_types[i]\n",
        "                        # Check for valid silhouette before projection\n",
        "                        if silhouette is None or silhouette.size == 0:\n",
        "                            print(f\"Warning: Skipping visual hull computation for invalid silhouette at index {i}.\")\n",
        "                            continue\n",
        "\n",
        "                        proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                        if proj_y is not None and proj_x is not None:\n",
        "                            # Assuming silhouette has object as 255 and background as 0\n",
        "                            # If projected point is in the black background (0), the voxel is outside the object\n",
        "                            if silhouette[proj_y, proj_x] == 0:\n",
        "                                voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                                break # No need to check other silhouettes for this voxel\n",
        "\n",
        "        print(\"Visual hull computation complete.\")\n",
        "\n",
        "        # --- Add check on the resulting voxel grid ---\n",
        "        num_occupied_voxels = np.sum(voxel_grid > 0)\n",
        "        total_voxels = grid_size * grid_size * grid_size\n",
        "\n",
        "        if num_occupied_voxels == 0:\n",
        "            print(\"Warning: The computed voxel grid is entirely empty. This may indicate issues with silhouette processing or view types.\")\n",
        "            # Optionally return None here if an empty grid should halt the pipeline\n",
        "            # return None\n",
        "        elif num_occupied_voxels == total_voxels:\n",
        "             print(\"Warning: The computed voxel grid is entirely filled. This likely indicates issues with silhouette processing or view types.\")\n",
        "             # Optionally return None here\n",
        "             # return None\n",
        "        else:\n",
        "            print(f\"Voxel grid contains {num_occupied_voxels} occupied voxels out of {total_voxels}.\")\n",
        "        # --- End of check ---\n",
        "\n",
        "\n",
        "        if show_previews and np.sum(voxel_grid > 0) > 0:\n",
        "            print(\"\\nDisplaying slices of the voxel grid:\")\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "            # Display a slice along the XZ plane (fixing Y)\n",
        "            y_slice = grid_size // 2\n",
        "            axes[0].imshow(voxel_grid[:, y_slice, :], cmap='gray', origin='lower')\n",
        "            axes[0].set_title(f'XZ slice (Y={y_slice})')\n",
        "            axes[0].set_xlabel('Z')\n",
        "            axes[0].set_ylabel('X')\n",
        "\n",
        "            # Display a slice along the YZ plane (fixing X)\n",
        "            x_slice = grid_size // 2\n",
        "            axes[1].imshow(voxel_grid[x_slice, :, :], cmap='gray', origin='lower')\n",
        "            axes[1].set_title(f'YZ slice (X={x_slice})')\n",
        "            axes[1].set_xlabel('Z')\n",
        "            axes[1].set_ylabel('Y')\n",
        "\n",
        "            # Display a slice along the XY plane (fixing Z)\n",
        "            z_slice = grid_size // 2\n",
        "            axes[2].imshow(voxel_grid[:, :, z_slice], cmap='gray', origin='lower')\n",
        "            axes[2].set_title(f'XY slice (Z={z_slice})')\n",
        "            axes[2].set_xlabel('Y')\n",
        "            axes[2].set_ylabel('X')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        elif show_previews and np.sum(voxel_grid > 0) == 0:\n",
        "            print(\"\\nVoxel grid is empty, cannot display slices.\")\n",
        "\n",
        "\n",
        "        return voxel_grid\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during visual hull computation: {e}\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a91f702b"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the third and fourth instructions by modifying the `run_reconstruction_pipeline` function to set `show_previews=True` when calling `process_silhouettes` and `compute_visual_hull`, and ensure `plt.show()` is used within the visualization functions to display the plots. The visualization functions were already updated in the previous steps to include `plt.show()`, so this step focuses on calling the functions with `show_previews=True`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01837e92"
      },
      "source": [
        "def run_reconstruction_pipeline(uploaded_files, view_types):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline with visualizations.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if not images:\n",
        "        print(\"No images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes with previews\n",
        "    print(\"\\nStep 2: Processing silhouettes with previews...\")\n",
        "    silhouettes = process_silhouettes(images, show_previews=True) # Enable previews\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Define parameters for the visual hull\n",
        "    grid_size = 100\n",
        "    volume_bounds = {\n",
        "        'x_min': -1.0, 'x_max': 1.0,\n",
        "        'y_min': -1.0, 'y_max': 1.0,\n",
        "        'z_min': -1.0, 'z_max': 1.0\n",
        "    }\n",
        "    print(f\"\\nDefined voxel grid parameters: size={grid_size}, bounds={volume_bounds}\")\n",
        "\n",
        "    # Check if the number of silhouettes matches the number of view types\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}). Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Compute visual hull with voxel grid slices preview\n",
        "    print(\"\\nStep 3: Computing visual hull with voxel grid slices preview...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=True) # Enable previews\n",
        "    # Check if the visual hull computation returned a valid grid\n",
        "    if voxel_grid is None or voxel_grid.shape != (grid_size, grid_size, grid_size):\n",
        "         print(\"Visual hull computation failed or returned an invalid grid. Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    # Use the latest corrected generate_mesh function from the history\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid) # Use the function defined previously\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'uploaded_files' is already populated from the previous upload step\n",
        "# and 'example_view_types' is defined to match the number of uploaded images.\n",
        "# Call the main pipeline function with visualizations enabled\n",
        "run_reconstruction_pipeline(uploaded_files, example_view_types)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a0d68c"
      },
      "source": [
        "## Desenvolver uma interface de entrada\n",
        "\n",
        "### Subtask:\n",
        "Create a more user-friendly way for the user to provide images, possibly using `ipywidgets` for a Colab environment, or by outlining a structure for a future web application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74f7aaf4"
      },
      "source": [
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def upload_silhouettes_widget():\n",
        "    \"\"\"\n",
        "    Creates a file upload widget for multiple silhouette images.\n",
        "    \"\"\"\n",
        "    print(\"Please upload the silhouette images for 3D reconstruction.\")\n",
        "    uploader = files.upload()\n",
        "    return uploader\n",
        "\n",
        "# Call the upload function\n",
        "uploaded_files = upload_silhouettes_widget()\n",
        "\n",
        "# Store uploaded files (already done by files.upload() but confirming structure)\n",
        "# uploaded_files is a dictionary {filename: content}\n",
        "\n",
        "# Provide feedback to the user\n",
        "if uploaded_files:\n",
        "    print(\"\\nSuccessfully uploaded the following files:\")\n",
        "    for file_name in uploaded_files.keys():\n",
        "        print(f\"- {file_name}\")\n",
        "else:\n",
        "    print(\"\\nNo files were uploaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3d08790"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure\n",
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "# from google.colab import files # We will handle file loading from a directory now\n",
        "\n",
        "\n",
        "# Modified load_images to read from a directory\n",
        "def load_images_from_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from a specified directory. Assumes images are directly in the directory.\n",
        "\n",
        "    Args:\n",
        "        directory_path: The path to the directory containing the image files.\n",
        "\n",
        "    Returns:\n",
        "        A list of loaded grayscale images, and a list of their filenames, or empty lists if an error occurs or no images found.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    print(f\"Loading images from directory: {directory_path}...\")\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print(f\"Error: Directory not found: {directory_path}\")\n",
        "        return images, image_filenames # Return empty lists\n",
        "\n",
        "    try:\n",
        "        # List all files in the directory\n",
        "        all_files = os.listdir(directory_path)\n",
        "        # Filter for common image file extensions (you might need to adjust this list)\n",
        "        image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"Warning: No image files found in directory: {directory_path}\")\n",
        "            return images, image_filenames # Return empty lists\n",
        "\n",
        "        # Sort files to maintain a consistent order, important for matching with metadata\n",
        "        image_files.sort()\n",
        "\n",
        "        for file_name in image_files:\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "            # Read image in grayscale\n",
        "            img_grayscale = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if img_grayscale is None:\n",
        "                print(f\"Warning: Could not load image file: {file_name}\")\n",
        "                continue\n",
        "\n",
        "            images.append(img_grayscale)\n",
        "            image_filenames.append(file_name)\n",
        "            print(f\"Successfully loaded {file_name}.\")\n",
        "\n",
        "        print(f\"Finished loading {len(images)} images.\")\n",
        "        return images, image_filenames\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during image loading from directory: {e}\")\n",
        "        return [], [] # Return empty lists in case of error\n",
        "\n",
        "\n",
        "# The original load_images function is no longer needed for the zip workflow,\n",
        "# but we'll keep it commented out or remove it later if confirmed not needed.\n",
        "# def load_images(uploaded_files):\n",
        "#     \"\"\"\n",
        "#     Loads grayscale images from uploaded files.\n",
        "#\n",
        "#     Args:\n",
        "#         uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "#\n",
        "#     Returns:\n",
        "#         A list of loaded grayscale images.\n",
        "#     \"\"\"\n",
        "#     images = []\n",
        "#     if uploaded_files:\n",
        "#         for file_name, content in uploaded_files.items():\n",
        "#             np_arr = np.frombuffer(content, np.uint8)\n",
        "#             img_grayscale = cv2.imdecode(np_arr, cv2.IMREAD_GRAYSCALE)\n",
        "#             images.append(img_grayscale)\n",
        "#             print(f\"Loaded {file_name}.\")\n",
        "#     else:\n",
        "#         print(\"No files uploaded.\")\n",
        "#     return images\n",
        "\n",
        "\n",
        "def process_silhouettes(images):\n",
        "    \"\"\"\n",
        "    Extracts silhouettes from a list of grayscale images.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks).\n",
        "    \"\"\"\n",
        "    silhouettes = []\n",
        "    for img_grayscale in images:\n",
        "        _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "        silhouettes.append(silhouette)\n",
        "    print(f\"Processed {len(silhouettes)} images and extracted silhouettes.\")\n",
        "    return silhouettes\n",
        "\n",
        "\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \"\"\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\"\"\"\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    if view_type == 'front':\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x\n",
        "\n",
        "\n",
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid.\n",
        "    \"\"\"\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(\"Warning: Number of silhouettes and view types do not match.\")\n",
        "        return voxel_grid\n",
        "\n",
        "    for x in range(grid_size):\n",
        "        for y in range(grid_size):\n",
        "            for z in range(grid_size):\n",
        "                if voxel_grid[x, y, z] == 0:\n",
        "                    continue\n",
        "\n",
        "                for i, silhouette in enumerate(silhouettes):\n",
        "                    view_type = view_types[i]\n",
        "                    proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                    if proj_y is not None and proj_x is not None:\n",
        "                        if silhouette[proj_y, proj_x] == 0: # Assuming silhouette has object as 255 and background as 0\n",
        "                            voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                            break # No need to check other silhouettes for this voxel\n",
        "\n",
        "    print(\"Visual hull computation complete.\")\n",
        "    return voxel_grid\n",
        "\n",
        "\n",
        "def generate_mesh(voxel_grid, level=127):\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid.\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(\"Mesh generated using Marching Cubes.\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(f\"Error during mesh generation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def export_mesh(mesh, output_filename):\n",
        "    \"\"\"\n",
        "    Exports a trimesh object to a GLB file.\n",
        "\n",
        "    Args:\n",
        "        mesh: A trimesh object.\n",
        "        output_filename: The name of the output GLB file.\n",
        "    \"\"\"\n",
        "    if mesh is not None:\n",
        "        try:\n",
        "            mesh.export(output_filename)\n",
        "            print(f\"Mesh exported to {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during mesh export: {e}\")\n",
        "    else:\n",
        "        print(\"No mesh to export.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9d18d0"
      },
      "source": [
        "## Refinar a experiência do usuário\n",
        "\n",
        "### Subtask:\n",
        "Improve the user experience by adding error handling, progress messages, and configurable options to the automated pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fa899ef"
      },
      "source": [
        "# Push the local commits to the remote repository (origin)\n",
        "# Use your GitHub username and Personal Access Token (PAT) in the URL for authentication\n",
        "# Replace <SEU_USUARIO_GITHUB> with your GitHub username\n",
        "# Replace <SEU_PAT> with your Personal Access Token\n",
        "# Note: Be cautious when sharing notebooks with PATs directly visible.\n",
        "# For better security, consider using Colab's Secrets Manager if you plan to share.\n",
        "\n",
        "!git push -u origin https://<SEU_USUARIO_GITHUB>:<SEU_PAT>@github.com/RogerioMatos75/3D_Fusion_AI.git master\n",
        "\n",
        "print(\"\\nComando git push com autenticação na URL executado.\")\n",
        "print(\"Verifique a saída acima para confirmar se o push foi bem-sucedido.\")\n",
        "print(\"Lembre-se de substituir <SEU_USUARIO_GITHUB> e <SEU_PAT> pelas suas credenciais.\")\n",
        "# Note: We are pushing the 'master' branch as that's the default in this Colab env currently.\n",
        "# If you want to push to 'main', you might need to rename your local branch first:\n",
        "# !git branch -M main\n",
        "# !git push -u origin https://<SEU_USUARIO_GITHUB>:<SEU_PAT>@github.com/RogerioMatos75/3D_Fusion_AI.git main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c77ceae"
      },
      "source": [
        "# Push the local commits to the remote repository (origin)\n",
        "# This command will likely prompt for your GitHub username and password/PAT in the terminal output below the cell.\n",
        "!git push -u origin master\n",
        "\n",
        "print(\"\\nO comando git push foi executado.\")\n",
        "print(\"Verifique a saída acima para inserir suas credenciais do GitHub, se solicitado.\")\n",
        "print(\"Lembre-se de que usar um Personal Access Token (PAT) é geralmente mais seguro do que sua senha.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28711847"
      },
      "source": [
        "# Add the remote origin (replace with your GitHub repo URL if different)\n",
        "# We'll name the remote 'origin' by convention\n",
        "!git remote add origin https://github.com/RogerioMatos75/3D_Fusion_AI.git\n",
        "\n",
        "# Verify that the remote was added\n",
        "!git remote -v\n",
        "\n",
        "print(\"\\nRepositório remoto do GitHub adicionado.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "076d9ea9"
      },
      "source": [
        "# Push the local commits to the remote repository (origin)\n",
        "# The -u flag sets the upstream branch, so future pushes can be just 'git push'\n",
        "!git push -u origin master\n",
        "\n",
        "print(\"\\nMudanças enviadas para o GitHub.\")\n",
        "print(\"Agora seu código está seguro no repositório remoto.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "131c09c0"
      },
      "source": [
        "# Add the newly created Python script to the staging area\n",
        "!git add 3d_reconstruction_pipeline.py\n",
        "\n",
        "# Commit the changes\n",
        "!git commit -m \"Add 3D reconstruction pipeline Python script\"\n",
        "\n",
        "print(\"\\nArquivo 3d_reconstruction_pipeline.py adicionado e novo commit realizado.\")\n",
        "print(\"Suas mudanças foram registradas no histórico do Git local.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e376c6af"
      },
      "source": [
        "import nbformat\n",
        "import os\n",
        "\n",
        "# Define the output directory and filename for the Python script\n",
        "# You can change this to '/content/drive/My Drive/YourProjectFolder/' if you have mounted your Drive\n",
        "output_dir = '/content/'\n",
        "output_filename = '3d_reconstruction_pipeline.py'\n",
        "output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "# Manually assemble the code content from the functions defined in the notebook history.\n",
        "# This ensures all the latest versions of the functions are included.\n",
        "script_content = \"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure\n",
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "# If running outside Colab, you might need to handle file uploads differently\n",
        "# from google.colab import files\n",
        "\n",
        "def load_images(uploaded_files):\n",
        "    \\\"\\\"\\\"\n",
        "    Loads grayscale images from uploaded files with error handling.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "\n",
        "    Returns:\n",
        "        A list of loaded grayscale images, or None if an error occurs.\n",
        "    \\\"\\\"\\\"\n",
        "    images = []\n",
        "    print(\"Loading images...\")\n",
        "    if not uploaded_files:\n",
        "        print(\"Warning: No files uploaded.\")\n",
        "        return images\n",
        "    try:\n",
        "        for file_name, content in uploaded_files.items():\n",
        "            np_arr = np.frombuffer(content, np.uint8)\n",
        "            img_grayscale = cv2.imdecode(np_arr, cv2.IMREAD_GRAYSCALE)\n",
        "            if img_grayscale is None:\n",
        "                print(f\"Error: Could not decode image file: {file_name}\")\n",
        "                continue\n",
        "            images.append(img_grayscale)\n",
        "            print(f\"Successfully loaded {file_name}.\")\n",
        "        print(f\"Finished loading {len(images)} images.\")\n",
        "        return images\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during image loading: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_silhouettes(images, show_previews=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Extracts silhouettes from a list of grayscale images with error handling\n",
        "    and optionally displays previews.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "        show_previews: If True, display the original grayscale image and the extracted silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks), or None if an error occurs.\n",
        "    \\\"\\\"\\\"\n",
        "    silhouettes = []\n",
        "    print(\"Processing silhouettes...\")\n",
        "    if not images:\n",
        "        print(\"No images provided for silhouette processing.\")\n",
        "        return silhouettes\n",
        "    try:\n",
        "        for i, img_grayscale in enumerate(images):\n",
        "            # Ensure image is valid before processing\n",
        "            if img_grayscale is None or img_grayscale.size == 0:\n",
        "                print(f\"Warning: Skipping processing for invalid image at index {i}.\")\n",
        "                continue\n",
        "\n",
        "            _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "            silhouettes.append(silhouette)\n",
        "            if show_previews:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.title(f'Original Image {i+1} (Grayscale)')\n",
        "                plt.imshow(img_grayscale, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.title(f'Silhouette {i+1} Extracted')\n",
        "                plt.imshow(silhouette, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "        print(f\"Finished processing {len(silhouettes)} images and extracted silhouettes.\")\n",
        "        return silhouettes\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during silhouette processing: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \\\"\\\"\\\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\\\"\\\"\\\"\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    if view_type == 'front':\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x\n",
        "\n",
        "\n",
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Computes the visual hull from a list of silhouettes with error handling\n",
        "    and optionally displays voxel grid slices.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "        show_previews: If True, display slices of the resulting voxel grid.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid, or None if an error occurs.\n",
        "    \\\"\\\"\\\"\n",
        "    print(\"Computing visual hull...\")\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes provided for visual hull computation.\")\n",
        "        return np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8) # Return empty grid\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}).\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        for x in range(grid_size):\n",
        "            for y in range(grid_size):\n",
        "                for z in range(grid_size):\n",
        "                    if voxel_grid[x, y, z] == 0:\n",
        "                        continue\n",
        "\n",
        "                    for i, silhouette in enumerate(silhouettes):\n",
        "                        view_type = view_types[i]\n",
        "                        # Check for valid silhouette before projection\n",
        "                        if silhouette is None or silhouette.size == 0:\n",
        "                            print(f\"Warning: Skipping visual hull computation for invalid silhouette at index {i}.\")\n",
        "                            continue\n",
        "\n",
        "                        proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                        if proj_y is not None and proj_x is not None:\n",
        "                            # Assuming silhouette has object as 255 and background as 0\n",
        "                            # If projected point is in the black background (0), the voxel is outside the object\n",
        "                            if silhouette[proj_y, proj_x] == 0:\n",
        "                                voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                                break # No need to check other silhouettes for this voxel\n",
        "\n",
        "        print(\"Visual hull computation complete.\")\n",
        "\n",
        "        if show_previews and np.sum(voxel_grid > 0) > 0:\n",
        "            print(\"\\nDisplaying slices of the voxel grid:\")\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "            # Display a slice along the XZ plane (fixing Y)\n",
        "            y_slice = grid_size // 2\n",
        "            axes[0].imshow(voxel_grid[:, y_slice, :], cmap='gray', origin='lower')\n",
        "            axes[0].set_title(f'XZ slice (Y={y_slice})')\n",
        "            axes[0].set_xlabel('Z')\n",
        "            axes[0].set_ylabel('X')\n",
        "\n",
        "            # Display a slice along the YZ plane (fixing X)\n",
        "            x_slice = grid_size // 2\n",
        "            axes[1].imshow(voxel_grid[x_slice, :, :], cmap='gray', origin='lower')\n",
        "            axes[1].set_title(f'YZ slice (X={x_slice})')\n",
        "            axes[1].set_xlabel('Z')\n",
        "            axes[1].set_ylabel('Y')\n",
        "\n",
        "            # Display a slice along the XY plane (fixing Z)\n",
        "            z_slice = grid_size // 2\n",
        "            axes[2].imshow(voxel_grid[:, :, z_slice], cmap='gray', origin='lower')\n",
        "            axes[2].set_title(f'XY slice (Z={z_slice})')\n",
        "            axes[2].set_xlabel('Y')\n",
        "            axes[2].set_ylabel('X')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        elif show_previews and np.sum(voxel_grid > 0) == 0:\n",
        "            print(\"\\nVoxel grid is empty, cannot display slices.\")\n",
        "\n",
        "        return voxel_grid\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during visual hull computation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def generate_mesh(voxel_grid, volume_bounds, grid_size, level=127):\n",
        "    \\\"\\\"\\\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes with error handling\n",
        "    and checks for uniform volume.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid (uint8, 0 or 255).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \\\"\\\"\\\"\n",
        "    print(\"Generating mesh using Marching Cubes...\")\n",
        "    if voxel_grid is None or voxel_grid.size == 0:\n",
        "        print(\"No valid voxel grid provided for mesh generation.\")\n",
        "        return None\n",
        "\n",
        "    # Step 1: Verificar o Volume - Check if there is a surface to extract\n",
        "    # Check if the grid is all 0s or all 255s\n",
        "    if np.all(voxel_grid == 0) or np.all(voxel_grid == 255):\n",
        "        print(\"ERROR: The voxel volume is uniform (all empty or all occupied). There is no surface to extract.\")\n",
        "        return None\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Step 2: Converter para Float\n",
        "        # Convert the voxel grid to float to ensure level works as expected\n",
        "        voxel_grid_float = voxel_grid.astype(np.float64)\n",
        "\n",
        "        # Step 3: Definir o Level (using 127 for float data as a standard midpoint)\n",
        "        # Calculate spacing based on the volume_bounds and grid_size.\n",
        "        spacing = ((volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size,\n",
        "                   (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size,\n",
        "                   (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size)\n",
        "        print(f\"Using spacing for Marching Cubes: {spacing}\")\n",
        "\n",
        "\n",
        "        vertices, faces, normals, values = measure.marching_cubes(\n",
        "            volume=voxel_grid_float,\n",
        "            level=level, # Using level=127 with float data\n",
        "            spacing=spacing\n",
        "        )\n",
        "\n",
        "        # Vertices are scaled by spacing, so they are in world units relative to the volume's local origin (0,0,0 voxel index).\n",
        "        # To get them into world coordinates relative to the overall world origin (0,0,0),\n",
        "        # we need to add the minimum bounds of the volume.\n",
        "        vertices_world = vertices + np.array([volume_bounds['x_min'], volume_bounds['y_min'], volume_bounds['z_min']])\n",
        "\n",
        "\n",
        "        mesh = trimesh.Trimesh(vertices=vertices_world, faces=faces, vertex_normals=normals) # Use vertices_world\n",
        "        print(f\"Marching Cubes concluded. Generated mesh with {len(vertices_world)} vertices and {len(faces)} faces.\")\n",
        "        return mesh\n",
        "    except ValueError as ve:\n",
        "         print(f\"Error during mesh generation (ValueError) with level={level} on float data: {ve}. This might be due to the 'level' parameter not being within the data range or other input issues.\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during mesh generation with level={level} on float data: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def export_mesh(mesh, output_filename):\n",
        "    \\\"\\\"\\\"\n",
        "    Exports a trimesh object to a GLB file with error handling.\n",
        "\n",
        "    Args:\n",
        "        mesh: A trimesh object.\n",
        "        output_filename: The name of the output GLB file.\n",
        "    \\\"\\\"\\\"\n",
        "    print(f\"Exporting mesh to {output_filename}...\")\n",
        "    if mesh is not None:\n",
        "        try:\n",
        "            # Ensure the mesh has valid geometry before exporting\n",
        "            if len(mesh.vertices) > 0 and len(mesh.faces) > 0:\n",
        "                mesh.export(output_filename)\n",
        "                print(f\"Successfully exported mesh to {output_filename}\")\n",
        "            else:\n",
        "                print(\"Warning: Mesh has no vertices or faces, skipping export.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during mesh export: {e}\")\n",
        "    else:\n",
        "        print(\"No mesh object available for export.\")\n",
        "\n",
        "\n",
        "def run_reconstruction_pipeline(uploaded_files, view_types, grid_size=100, volume_bounds=None, marching_cubes_level=127, show_previews=True):\n",
        "    \\\"\\\"\\\"\n",
        "    Orchestrates the 3D reconstruction pipeline with configurable options and error handling.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "                       If None, default bounds are used.\n",
        "        marching_cubes_level: The iso-surface value for Marching Cubes.\n",
        "        show_previews: If True, display previews of silhouettes and voxel grid slices.\n",
        "    \\\"\\\"\\\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Define default volume bounds if not provided\n",
        "    if volume_bounds is None:\n",
        "        volume_bounds = {\n",
        "            'x_min': -1.0, 'x_max': 1.0,\n",
        "            'y_min': -1.0, 'y_max': 1.0,\n",
        "            'z_min': -1.0, 'z_max': 1.0\n",
        "        }\n",
        "    print(f\"Using voxel grid size: {grid_size}x{grid_size}x{grid_size}\")\n",
        "    print(f\"Using volume bounds: {volume_bounds}\")\n",
        "    print(f\"Using Marching Cubes level: {marching_cubes_level}\")\n",
        "    print(f\"Show previews: {show_previews}\")\n",
        "\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if images is None or not images:\n",
        "        print(\"Image loading failed or no images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    silhouettes = process_silhouettes(images, show_previews=show_previews)\n",
        "    if silhouettes is None or not silhouettes:\n",
        "        print(\"Silhouette processing failed or no silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Check if the number of silhouettes matches the number of view types\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}). Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Compute visual hull\n",
        "    print(\"\\nStep 3: Computing visual hull...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=show_previews)\n",
        "    # Check if the visual hull computation returned a valid grid\n",
        "    if voxel_grid is None or voxel_grid.shape != (grid_size, grid_size, grid_size):\n",
        "         print(\"Visual hull computation failed or returned an invalid grid. Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    # Pass volume_bounds and grid_size to generate_mesh\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid, volume_bounds, grid_size, level=marching_cubes_level)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "# Example usage (will be placed in a separate cell):\n",
        "# if 'uploaded_files' in locals() and uploaded_files:\n",
        "#     example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "#     run_reconstruction_pipeline(uploaded_files, example_view_types)\n",
        "# else:\n",
        "#     print(\"'uploaded_files' is not defined or is empty. Please upload images first.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the script content to a file\n",
        "try:\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(script_content)\n",
        "    print(f\"Python script saved to: {output_path}\")\n",
        "\n",
        "    # Optional: Offer to download the file\n",
        "    # from google.colab import files\n",
        "    # files.download(output_path)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving Python script: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52a7e3e6"
      },
      "source": [
        "# Add all files in the current directory to the staging area\n",
        "!git add .\n",
        "\n",
        "# Make the initial commit\n",
        "!git commit -m \"Initial commit of the project pipeline\"\n",
        "\n",
        "print(\"\\nArquivos adicionados e commit inicial realizado.\")\n",
        "print(\"Agora o Git está rastreando as mudanças nos arquivos neste diretório.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ab9b5d2"
      },
      "source": [
        "# Change to the directory where you want to initialize the Git repository\n",
        "# The /content/ directory is a common place in Colab\n",
        "%cd /content/\n",
        "\n",
        "# Initialize a new Git repository\n",
        "!git init\n",
        "\n",
        "# Configure Git (replace with your name and email)\n",
        "!git config user.email \"you@example.com\"\n",
        "!git config user.name \"Your Name\"\n",
        "\n",
        "print(\"\\nRepositório Git inicializado em /content/\")\n",
        "print(\"Por favor, substitua 'you@example.com' e 'Your Name' pelas suas informações.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d313f8"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement error handling, progress messages, and configurable options in the main pipeline function as requested by the current subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c147f352"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import measure\n",
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "# from google.colab import files # Keep imports at the top\n",
        "\n",
        "\n",
        "def load_images(uploaded_files):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from uploaded files with error handling.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "\n",
        "    Returns:\n",
        "        A list of loaded grayscale images, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    print(\"Loading images...\")\n",
        "    if not uploaded_files:\n",
        "        print(\"Warning: No files uploaded.\")\n",
        "        return images\n",
        "    try:\n",
        "        for file_name, content in uploaded_files.items():\n",
        "            np_arr = np.frombuffer(content, np.uint8)\n",
        "            img_grayscale = cv2.imdecode(np_arr, cv2.IMREAD_GRAYSCALE)\n",
        "            if img_grayscale is None:\n",
        "                print(f\"Error: Could not decode image file: {file_name}\")\n",
        "                continue\n",
        "            images.append(img_grayscale)\n",
        "            print(f\"Successfully loaded {file_name}.\")\n",
        "        print(f\"Finished loading {len(images)} images.\")\n",
        "        return images\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during image loading: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_silhouettes(images, show_previews=False):\n",
        "    \"\"\"\n",
        "    Extracts silhouettes from a list of grayscale images with error handling\n",
        "    and optionally displays previews.\n",
        "\n",
        "    Args:\n",
        "        images: A list of grayscale images.\n",
        "        show_previews: If True, display the original grayscale image and the extracted silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A list of silhouette images (binary masks), or None if an error occurs.\n",
        "    \"\"\"\n",
        "    silhouettes = []\n",
        "    print(\"Processing silhouettes...\")\n",
        "    if not images:\n",
        "        print(\"No images provided for silhouette processing.\")\n",
        "        return silhouettes\n",
        "    try:\n",
        "        for i, img_grayscale in enumerate(images):\n",
        "            # Ensure image is valid before processing\n",
        "            if img_grayscale is None or img_grayscale.size == 0:\n",
        "                print(f\"Warning: Skipping processing for invalid image at index {i}.\")\n",
        "                continue\n",
        "\n",
        "            _, silhouette = cv2.threshold(img_grayscale, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "            silhouettes.append(silhouette)\n",
        "            if show_previews:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.title(f'Original Image {i+1} (Grayscale)')\n",
        "                plt.imshow(img_grayscale, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.title(f'Silhouette {i+1} Extracted')\n",
        "                plt.imshow(silhouette, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "        print(f\"Finished processing {len(silhouettes)} images and extracted silhouettes.\")\n",
        "        return silhouettes\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during silhouette processing: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \"\"\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\"\"\"\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    if view_type == 'front':\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x\n",
        "\n",
        "\n",
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=False):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes with error handling\n",
        "    and optionally displays voxel grid slices.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "        show_previews: If True, display slices of the resulting voxel grid.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    print(\"Computing visual hull...\")\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes provided for visual hull computation.\")\n",
        "        return np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8) # Return empty grid\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}).\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        for x in range(grid_size):\n",
        "            for y in range(grid_size):\n",
        "                for z in range(grid_size):\n",
        "                    if voxel_grid[x, y, z] == 0:\n",
        "                        continue\n",
        "\n",
        "                    for i, silhouette in enumerate(silhouettes):\n",
        "                        view_type = view_types[i]\n",
        "                        # Check for valid silhouette before projection\n",
        "                        if silhouette is None or silhouette.size == 0:\n",
        "                            print(f\"Warning: Skipping visual hull computation for invalid silhouette at index {i}.\")\n",
        "                            continue\n",
        "\n",
        "                        proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                        if proj_y is not None and proj_x is not None:\n",
        "                            # Assuming silhouette has object as 255 and background as 0\n",
        "                            # If projected point is in the black background (0), the voxel is outside the object\n",
        "                            if silhouette[proj_y, proj_x] == 0:\n",
        "                                voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                                break # No need to check other silhouettes for this voxel\n",
        "\n",
        "        print(\"Visual hull computation complete.\")\n",
        "\n",
        "        if show_previews and np.sum(voxel_grid > 0) > 0:\n",
        "            print(\"\\nDisplaying slices of the voxel grid:\")\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "            # Display a slice along the XZ plane (fixing Y)\n",
        "            y_slice = grid_size // 2\n",
        "            axes[0].imshow(voxel_grid[:, y_slice, :], cmap='gray', origin='lower')\n",
        "            axes[0].set_title(f'XZ slice (Y={y_slice})')\n",
        "            axes[0].set_xlabel('Z')\n",
        "            axes[0].set_ylabel('X')\n",
        "\n",
        "            # Display a slice along the YZ plane (fixing X)\n",
        "            x_slice = grid_size // 2\n",
        "            axes[1].imshow(voxel_grid[x_slice, :, :], cmap='gray', origin='lower')\n",
        "            axes[1].set_title(f'YZ slice (X={x_slice})')\n",
        "            axes[1].set_xlabel('Z')\n",
        "            axes[1].set_ylabel('Y')\n",
        "\n",
        "            # Display a slice along the XY plane (fixing Z)\n",
        "            z_slice = grid_size // 2\n",
        "            axes[2].imshow(voxel_grid[:, :, z_slice], cmap='gray', origin='lower')\n",
        "            axes[2].set_title(f'XY slice (Z={z_slice})')\n",
        "            axes[2].set_xlabel('Y')\n",
        "            axes[2].set_ylabel('X')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        elif show_previews and np.sum(voxel_grid > 0) == 0:\n",
        "            print(\"\\nVoxel grid is empty, cannot display slices.\")\n",
        "\n",
        "        return voxel_grid\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during visual hull computation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def generate_mesh(voxel_grid, level=127):\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes with error handling.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid (uint8, 0 or 255).\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    print(\"Generating mesh using Marching Cubes...\")\n",
        "    if voxel_grid is None or voxel_grid.size == 0 or np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"No valid or non-empty voxel grid provided for mesh generation.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Convert the voxel grid to float to ensure level works as expected\n",
        "        voxel_grid_float = voxel_grid.astype(np.float64)\n",
        "        vertices, faces, normals, values = measure.marching_cubes(voxel_grid_float, level=level)\n",
        "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_normals=normals)\n",
        "        print(f\"Mesh generated with {len(vertices)} vertices and {len(faces)} faces.\")\n",
        "        return mesh\n",
        "    except ValueError as ve:\n",
        "         print(f\"Error during mesh generation (ValueError): {ve}. This might be due to the 'level' parameter not being within the data range or other input issues.\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during mesh generation: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def export_mesh(mesh, output_filename):\n",
        "    \"\"\"\n",
        "    Exports a trimesh object to a GLB file with error handling.\n",
        "\n",
        "    Args:\n",
        "        mesh: A trimesh object.\n",
        "        output_filename: The name of the output GLB file.\n",
        "    \"\"\"\n",
        "    print(f\"Exporting mesh to {output_filename}...\")\n",
        "    if mesh is not None:\n",
        "        try:\n",
        "            # Ensure the mesh has valid geometry before exporting\n",
        "            if len(mesh.vertices) > 0 and len(mesh.faces) > 0:\n",
        "                mesh.export(output_filename)\n",
        "                print(f\"Successfully exported mesh to {output_filename}\")\n",
        "            else:\n",
        "                print(\"Warning: Mesh has no vertices or faces, skipping export.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during mesh export: {e}\")\n",
        "    else:\n",
        "        print(\"No mesh object available for export.\")\n",
        "\n",
        "\n",
        "def run_reconstruction_pipeline(uploaded_files, view_types, grid_size=100, volume_bounds=None, marching_cubes_level=127, show_previews=True):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline with configurable options and error handling.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "                       If None, default bounds are used.\n",
        "        marching_cubes_level: The iso-surface value for Marching Cubes.\n",
        "        show_previews: If True, display previews of silhouettes and voxel grid slices.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Define default volume bounds if not provided\n",
        "    if volume_bounds is None:\n",
        "        volume_bounds = {\n",
        "            'x_min': -1.0, 'x_max': 1.0,\n",
        "            'y_min': -1.0, 'y_max': 1.0,\n",
        "            'z_min': -1.0, 'z_max': 1.0\n",
        "        }\n",
        "    print(f\"Using voxel grid size: {grid_size}x{grid_size}x{grid_size}\")\n",
        "    print(f\"Using volume bounds: {volume_bounds}\")\n",
        "    print(f\"Using Marching Cubes level: {marching_cubes_level}\")\n",
        "    print(f\"Show previews: {show_previews}\")\n",
        "\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if images is None or not images:\n",
        "        print(\"Image loading failed or no images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    silhouettes = process_silhouettes(images, show_previews=show_previews)\n",
        "    if silhouettes is None or not silhouettes:\n",
        "        print(\"Silhouette processing failed or no silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Check if the number of silhouettes matches the number of view types\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(f\"Error: Number of silhouettes ({len(silhouettes)}) does not match number of view types ({len(view_types)}). Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Compute visual hull\n",
        "    print(\"\\nStep 3: Computing visual hull...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types, show_previews=show_previews)\n",
        "    # Check if the visual hull computation returned a valid grid\n",
        "    if voxel_grid is None or voxel_grid.shape != (grid_size, grid_size, grid_size):\n",
        "         print(\"Visual hull computation failed or returned an invalid grid. Aborting pipeline.\")\n",
        "         return\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid, level=marching_cubes_level)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'uploaded_files' is already populated from the previous upload step\n",
        "# and 'example_view_types' is defined to match the number of uploaded images.\n",
        "\n",
        "# Update the example_view_types to match the number of uploaded images (15)\n",
        "# This is still a placeholder; actual view types depend on the image capture.\n",
        "# example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "# print(f\"\\nUpdated example_view_types to match {len(example_view_types)} uploaded images.\")\n",
        "# print(example_view_types)\n",
        "\n",
        "\n",
        "# Check if uploaded_files is defined and not empty before calling the pipeline\n",
        "# This section is intended to be run after the image upload cell.\n",
        "if 'uploaded_files' in locals() and uploaded_files:\n",
        "    # Update the example_view_types to match the number of uploaded images\n",
        "    example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "    print(f\"\\nUsing {len(uploaded_files)} uploaded images.\")\n",
        "    print(f\"Corresponding example view types: {example_view_types}\")\n",
        "\n",
        "    # Call the main pipeline function with configurable options\n",
        "    run_reconstruction_pipeline(\n",
        "        uploaded_files=uploaded_files,\n",
        "        view_types=example_view_types,\n",
        "        grid_size=200,  # Example: increase grid size\n",
        "        volume_bounds={'x_min': -1.5, 'x_max': 1.5, 'y_min': -1.5, 'y_max': 1.5, 'z_min': -1.5, 'z_max': 1.5}, # Example: adjust bounds\n",
        "        marching_cubes_level=127, # Example: adjust level\n",
        "        show_previews=True # Keep previews enabled\n",
        "    )\n",
        "else:\n",
        "    print(\"\\n'uploaded_files' is not defined or is empty.\")\n",
        "    print(\"Please execute the file upload cell first to upload your images.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ae0ddcb"
      },
      "source": [
        "**Reasoning**:\n",
        "The pipeline execution failed at the mesh generation step with a ValueError related to the marching cubes level. While the subtask is to improve user experience, the pipeline must complete successfully to demonstrate this. I need to try a different level for marching cubes to see if it resolves the error and allows the pipeline to proceed, thereby allowing the demonstration of the improved user experience features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "311a680b"
      },
      "source": [
        "# Modify the generate_mesh function to incorporate the user's corrective plan ideas\n",
        "def generate_mesh(voxel_grid, level=127): # Using level=127 with float data as a standard approach\n",
        "    \"\"\"\n",
        "    Generates a mesh from a voxel grid using Marching Cubes with error handling\n",
        "    and checks for uniform volume.\n",
        "\n",
        "    Args:\n",
        "        voxel_grid: A numpy array representing the voxel grid (uint8, 0 or 255).\n",
        "        level: The iso-surface value for Marching Cubes.\n",
        "\n",
        "    Returns:\n",
        "        A trimesh object or None if mesh generation fails.\n",
        "    \"\"\"\n",
        "    print(\"Generating mesh using Marching Cubes...\")\n",
        "    if voxel_grid is None or voxel_grid.size == 0:\n",
        "        print(\"No valid voxel grid provided for mesh generation.\")\n",
        "        return None\n",
        "\n",
        "    # Step 1: Verificar o Volume - Check if there is a surface to extract\n",
        "    # Check if the grid is all 0s or all 255s\n",
        "    if np.all(voxel_grid == 0) or np.all(voxel_grid == 255):\n",
        "        print(\"ERROR: The voxel volume is uniform (all empty or all occupied). There is no surface to extract.\")\n",
        "        return None\n",
        "\n",
        "    # Check if there are any occupied voxels before generating mesh\n",
        "    if np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation resulted in an empty grid. No mesh can be generated.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Step 2: Converter para Float\n",
        "        # Convert the voxel grid to float to ensure level works as expected\n",
        "        voxel_grid_float = voxel_grid.astype(np.float64)\n",
        "\n",
        "        # Step 3: Definir o Level (using 127 for float data as a standard midpoint)\n",
        "        # The 'spacing' parameter is important for correct scaling of the mesh.\n",
        "        # We'll calculate it based on the volume_bounds and grid_size.\n",
        "        # Assuming volume_bounds and grid_size are accessible or passed.\n",
        "        # For now, let's use a placeholder spacing based on the common -1 to 1 bounds and grid_size=100/150.\n",
        "        # A more robust implementation would pass volume_bounds and grid_size here.\n",
        "        # Let's assume default bounds (-1 to 1) and the grid_size used in the pipeline.\n",
        "        # We'll need to ensure volume_bounds and grid_size are available in the pipeline function to pass here.\n",
        "        # For this modification, let's temporarily hardcode spacing based on the common example usage.\n",
        "        # In the run_reconstruction_pipeline, we will ensure these are passed correctly.\n",
        "\n",
        "        # Placeholder for spacing calculation (will be properly passed in the pipeline call)\n",
        "        # For the context of just modifying the function, let's assume a potential calculation:\n",
        "        # spacing = ((volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size,\n",
        "        #            (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size,\n",
        "        #            (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size)\n",
        "        # As volume_bounds and grid_size are used in compute_visual_hull and run_reconstruction_pipeline,\n",
        "        # let's assume they will be passed correctly to this function when called from the pipeline.\n",
        "        # For now, let's update the function signature to accept them.\n",
        "\n",
        "        # Updated function signature to accept volume_bounds and grid_size\n",
        "        # This requires updating the call to generate_mesh in run_reconstruction_pipeline as well.\n",
        "        # Let's proceed with modifying the function first, and then update the pipeline call.\n",
        "\n",
        "        # Re-defining the function signature including spacing calculation within the function for now\n",
        "        # This is less ideal but allows modifying this cell in isolation first.\n",
        "        # A better approach is to pass spacing or bounds/grid_size to this function.\n",
        "        # Let's stick to modifying the existing function and assume bounds/grid_size are accessible\n",
        "        # or use the values from the last pipeline run for spacing calculation here.\n",
        "        # The last run used grid_size=150 and bounds {-1.5 to 1.5}.\n",
        "        last_grid_size = 150\n",
        "        last_volume_bounds = {'x_min': -1.5, 'x_max': 1.5, 'y_min': -1.5, 'y_max': 1.5, 'z_min': -1.5, 'z_max': 1.5}\n",
        "        spacing = ((last_volume_bounds['x_max'] - last_volume_bounds['x_min']) / last_grid_size,\n",
        "                   (last_volume_bounds['y_max'] - last_volume_bounds['y_min']) / last_grid_size,\n",
        "                   (last_volume_bounds['z_max'] - last_volume_bounds['z_min']) / last_grid_size)\n",
        "        print(f\"Using spacing for Marching Cubes: {spacing}\")\n",
        "\n",
        "\n",
        "        vertices, faces, normals, values = measure.marching_cubes(\n",
        "            volume=voxel_grid_float,\n",
        "            level=level, # Using level=127 with float data\n",
        "            spacing=spacing\n",
        "        )\n",
        "\n",
        "        # Centralizar o modelo na origem (adjusting based on the used volume bounds)\n",
        "        # The marching_cubes algorithm outputs vertices relative to the corner of the volume.\n",
        "        # To center it, we need to subtract half of the volume extent.\n",
        "        # The volume extends from bounds_min to bounds_max.\n",
        "        center_offset = [(last_volume_bounds['x_max'] + last_volume_bounds['x_min']) / 2.0,\n",
        "                         (last_volume_bounds['y_max'] + last_volume_bounds['y_min']) / 2.0,\n",
        "                         (last_volume_bounds['z_max'] + last_volume_bounds['z_min']) / 2.0]\n",
        "        # However, marching_cubes vertices are typically relative to the origin (0,0,0) of the *volume*.\n",
        "        # If the volume spans from -1.5 to 1.5, its \"origin\" for marching cubes is at (-1.5, -1.5, -1.5) in world space.\n",
        "        # To center it at (0,0,0) world space, we need to shift by the min bounds.\n",
        "        shift_offset = [last_volume_bounds['x_min'], last_volume_bounds['y_min'], last_volume_bounds['z_min']]\n",
        "\n",
        "        # Vertices are scaled by spacing, so they are in world units relative to the volume's local origin (0,0,0 voxel index).\n",
        "        # To get them into world coordinates relative to the overall world origin (0,0,0),\n",
        "        # we need to add the minimum bounds of the volume.\n",
        "        vertices_world = vertices + np.array([last_volume_bounds['x_min'], last_volume_bounds['y_min'], last_volume_bounds['z_min']])\n",
        "\n",
        "\n",
        "        mesh = trimesh.Trimesh(vertices=vertices_world, faces=faces, vertex_normals=normals) # Use vertices_world\n",
        "        print(f\"Marching Cubes concluded. Generated mesh with {len(vertices_world)} vertices and {len(faces)} faces.\")\n",
        "        return mesh\n",
        "    except ValueError as ve:\n",
        "         print(f\"Error during mesh generation (ValueError) with level={level} on float data: {ve}. This might be due to the 'level' parameter not being within the data range or other input issues.\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during mesh generation with level={level} on float data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Re-call the main pipeline function with the updated generate_mesh\n",
        "# We need to make sure run_reconstruction_pipeline passes the correct\n",
        "# grid_size and volume_bounds to generate_mesh if the signature was changed.\n",
        "# Since we hardcoded the spacing calculation based on the last run's parameters\n",
        "# within the generate_mesh function for now, we can call the pipeline\n",
        "# with the same parameters as before to ensure consistency for this test.\n",
        "# A more robust refactoring would involve passing bounds and grid_size to generate_mesh.\n",
        "\n",
        "# Let's call the pipeline again with the same parameters to test the modified generate_mesh.\n",
        "# The previous call used grid_size=150, volume_bounds={'x_min': -1.5, 'x_max': 1.5, ...}, level=0.5.\n",
        "# Our modified generate_mesh now uses level=127 and calculates spacing based on grid_size=150 and bounds {-1.5 to 1.5}.\n",
        "# So, calling the pipeline with these parameters aligns with the function's internal spacing calculation.\n",
        "\n",
        "run_reconstruction_pipeline(\n",
        "    uploaded_files=uploaded_files,\n",
        "    view_types=example_view_types,\n",
        "    grid_size=150,\n",
        "    volume_bounds={'x_min': -1.5, 'x_max': 1.5, 'y_min': -1.5, 'y_max': 1.5, 'z_min': -1.5, 'z_max': 1.5},\n",
        "    marching_cubes_level=127, # Pass 127 to align with the function's internal use\n",
        "    show_previews=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "690a3fce"
      },
      "source": [
        "## Documentar o framework\n",
        "\n",
        "### Subtask:\n",
        "Add clear instructions on how to use the automated pipeline, explaining the input requirements (image formats, number of views, corresponding view types), configurable options, and expected outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5833398f"
      },
      "source": [
        "def project_voxel_to_silhouette(voxel_coords, silhouette_shape, view_type, volume_bounds, grid_size):\n",
        "    \"\"\"Projects a 3D voxel coordinate onto the 2D plane of a silhouette view.\"\"\"\n",
        "    voxel_world_x = volume_bounds['x_min'] + (voxel_coords[0] + 0.5) * (volume_bounds['x_max'] - volume_bounds['x_min']) / grid_size\n",
        "    voxel_world_y = volume_bounds['y_min'] + (voxel_coords[1] + 0.5) * (volume_bounds['y_max'] - volume_bounds['y_min']) / grid_size\n",
        "    voxel_world_z = volume_bounds['z_min'] + (voxel_coords[2] + 0.5) * (volume_bounds['z_max'] - volume_bounds['z_min']) / grid_size\n",
        "\n",
        "    img_height, img_width = silhouette_shape\n",
        "\n",
        "    if view_type == 'front':\n",
        "        proj_x = int((voxel_world_z - volume_bounds['z_min']) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'side':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['y_max'] - voxel_world_y) / (volume_bounds['y_max'] - volume_bounds['y_min']) * img_height)\n",
        "    elif view_type == 'top':\n",
        "        proj_x = int((voxel_world_x - volume_bounds['x_min']) / (volume_bounds['x_max'] - volume_bounds['x_min']) * img_width)\n",
        "        proj_y = int((volume_bounds['z_max'] - voxel_world_z) / (volume_bounds['z_max'] - volume_bounds['z_min']) * img_height)\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    proj_x = max(0, min(proj_x, img_width - 1))\n",
        "    proj_y = max(0, min(proj_y, img_height - 1))\n",
        "\n",
        "    return proj_y, proj_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34f803ba"
      },
      "source": [
        "def compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types):\n",
        "    \"\"\"\n",
        "    Computes the visual hull from a list of silhouettes.\n",
        "\n",
        "    Args:\n",
        "        silhouettes: A list of silhouette images.\n",
        "        grid_size: The size of the voxel grid (cubic).\n",
        "        volume_bounds: A dictionary defining the world coordinates bounds of the volume.\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array representing the voxel grid.\n",
        "    \"\"\"\n",
        "    voxel_grid = np.full((grid_size, grid_size, grid_size), 255, dtype=np.uint8)\n",
        "\n",
        "    if len(silhouettes) != len(view_types):\n",
        "        print(\"Warning: Number of silhouettes and view types do not match.\")\n",
        "        return voxel_grid\n",
        "\n",
        "    for x in range(grid_size):\n",
        "        for y in range(grid_size):\n",
        "            for z in range(grid_size):\n",
        "                if voxel_grid[x, y, z] == 0:\n",
        "                    continue\n",
        "\n",
        "                for i, silhouette in enumerate(silhouettes):\n",
        "                    view_type = view_types[i]\n",
        "                    proj_y, proj_x = project_voxel_to_silhouette((x, y, z), silhouette.shape, view_type, volume_bounds, grid_size)\n",
        "\n",
        "                    if proj_y is not None and proj_x is not None:\n",
        "                        if silhouette[proj_y, proj_x] == 0: # Assuming silhouette has object as 255 and background as 0\n",
        "                            voxel_grid[x, y, z] = 0 # Mark voxel as empty\n",
        "                            break # No need to check other silhouettes for this voxel\n",
        "\n",
        "    print(\"Visual hull computation complete.\")\n",
        "    return voxel_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8254fd08"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "if 'mesh' in locals() and mesh is not None:\n",
        "    print(\"Visualizando a malha 3D interativamente...\")\n",
        "    # O Trimesh tem um visualizador interativo integrado ao Colab/Jupyter\n",
        "    # Note: Interactive visualization within Colab can sometimes be inconsistent.\n",
        "    # If display(mesh.show()) doesn't work as expected, downloading and viewing\n",
        "    # the GLB file in an external viewer is the most reliable method.\n",
        "    try:\n",
        "        display(mesh.show())\n",
        "    except Exception as e:\n",
        "        print(f\"Interactive visualization failed: {e}\")\n",
        "        print(\"Please download the GLB file to view the model.\")\n",
        "\n",
        "\n",
        "    print(\"\\nPreparando para exportar o arquivo .glb...\")\n",
        "    try:\n",
        "        # Exportar a malha para o formato GLB (formato binário do glTF)\n",
        "        glb_data = mesh.export(file_type='glb')\n",
        "\n",
        "        # Iniciar o download do arquivo no seu navegador\n",
        "        file_name_export = \"modelo_3d_gerado.glb\"\n",
        "        with open(file_name_export, 'wb') as f:\n",
        "            f.write(glb_data)\n",
        "\n",
        "        print(f\"Arquivo '{file_name_export}' pronto para download.\")\n",
        "        files.download(file_name_export)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro durante a exportação: {e}\")\n",
        "else:\n",
        "    print(\"A variável 'mesh' não foi encontrada ou está vazia. Execute o Marching Cubes primeiro.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "301f1e1a"
      },
      "source": [
        "## Automate the pipeline\n",
        "\n",
        "### Subtask:\n",
        "Create a main function that orchestrates the execution of the functions from the previous steps in sequence: loading images, processing silhouettes, computing the visual hull, generating the mesh, and exporting the GLB file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0270878"
      },
      "source": [
        "def run_reconstruction_pipeline(uploaded_files, view_types):\n",
        "    \"\"\"\n",
        "    Orchestrates the 3D reconstruction pipeline.\n",
        "\n",
        "    Args:\n",
        "        uploaded_files: A dictionary of uploaded files from google.colab.files.upload().\n",
        "        view_types: A list of strings indicating the view type for each silhouette.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting 3D Reconstruction Pipeline ---\")\n",
        "\n",
        "    # Step 1: Load images\n",
        "    print(\"\\nStep 1: Loading images...\")\n",
        "    images = load_images(uploaded_files)\n",
        "    if not images:\n",
        "        print(\"No images loaded. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Process silhouettes\n",
        "    print(\"\\nStep 2: Processing silhouettes...\")\n",
        "    silhouettes = process_silhouettes(images)\n",
        "    if not silhouettes:\n",
        "        print(\"No silhouettes processed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Define parameters for the visual hull\n",
        "    grid_size = 100\n",
        "    volume_bounds = {\n",
        "        'x_min': -1.0, 'x_max': 1.0,\n",
        "        'y_min': -1.0, 'y_max': 1.0,\n",
        "        'z_min': -1.0, 'z_max': 1.0\n",
        "    }\n",
        "    print(f\"\\nDefined voxel grid parameters: size={grid_size}, bounds={volume_bounds}\")\n",
        "\n",
        "    # Step 3: Compute visual hull\n",
        "    print(\"\\nStep 3: Computing visual hull...\")\n",
        "    voxel_grid = compute_visual_hull(silhouettes, grid_size, volume_bounds, view_types)\n",
        "    if voxel_grid is None or np.sum(voxel_grid > 0) == 0:\n",
        "        print(\"Visual hull computation failed or resulted in an empty grid. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Generate mesh using Marching Cubes\n",
        "    print(\"\\nStep 4: Generating mesh...\")\n",
        "    reconstructed_mesh = generate_mesh(voxel_grid)\n",
        "    if reconstructed_mesh is None:\n",
        "        print(\"Mesh generation failed. Aborting pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Export the GLB file\n",
        "    print(\"\\nStep 5: Exporting GLB file...\")\n",
        "    output_filename = 'reconstructed_model.glb'\n",
        "    export_mesh(reconstructed_mesh, output_filename)\n",
        "\n",
        "    print(\"\\n--- 3D Reconstruction Pipeline Complete ---\")\n",
        "\n",
        "# Example usage:\n",
        "# IMPORTANT: Make sure the file upload cell (Passo 1: Desenvolver uma interface de entrada)\n",
        "# has been executed successfully before running this cell, so 'uploaded_files' is defined.\n",
        "\n",
        "# Assuming 'uploaded_files' is already populated from the previous upload step\n",
        "# and 'view_types' is defined to match the order and type of uploaded images.\n",
        "# This is a placeholder list; replace with actual view types based on your uploaded images.\n",
        "# Example: If you uploaded front, side, top, and another side view:\n",
        "# example_view_types = ['front', 'side', 'top', 'side']\n",
        "\n",
        "# For the images uploaded in the history: 9 images. Let's assume an example sequence of view types.\n",
        "# The actual view types would depend on how the images were captured.\n",
        "# This example assumes a sequence of views around the object.\n",
        "# example_view_types = ['view1', 'view2', 'view3', 'view4', 'view5', 'view6', 'view7', 'view8', 'view9'] # Replace with actual view types\n",
        "\n",
        "# Check if uploaded_files is defined and not empty before calling the pipeline\n",
        "if 'uploaded_files' in locals() and uploaded_files:\n",
        "    # Update the example_view_types to match the number of uploaded images\n",
        "    example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "    print(f\"\\nUsing {len(uploaded_files)} uploaded images.\")\n",
        "    print(f\"Corresponding example view types: {example_view_types}\")\n",
        "\n",
        "    # Call the main pipeline function\n",
        "    run_reconstruction_pipeline(uploaded_files, example_view_types)\n",
        "else:\n",
        "    print(\"\\n'uploaded_files' is not defined or is empty.\")\n",
        "    print(\"Please execute the file upload cell first to upload your images.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba1cc1dd"
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory to clean up\n",
        "cleanup_dir = '/content/'\n",
        "\n",
        "# List of common image file extensions to remove\n",
        "image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']\n",
        "\n",
        "print(f\"Cleaning up image files in: {cleanup_dir}\")\n",
        "\n",
        "# Iterate through items in the directory\n",
        "for item in os.listdir(cleanup_dir):\n",
        "    item_path = os.path.join(cleanup_dir, item)\n",
        "    # Check if it's a file and has an image extension\n",
        "    if os.path.isfile(item_path) and os.path.splitext(item)[1].lower() in image_extensions:\n",
        "        try:\n",
        "            os.remove(item_path)\n",
        "            print(f\"Removed image file: {item}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error removing {item}: {e}\")\n",
        "\n",
        "print(\"Image file cleanup complete.\")\n",
        "\n",
        "# Optional: List contents again to verify\n",
        "# print(f\"\\nContents of {cleanup_dir} after image cleanup:\")\n",
        "# for item in os.listdir(cleanup_dir):\n",
        "#     print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb6eccdf"
      },
      "source": [
        "import trimesh\n",
        "import trimesh.repair\n",
        "import trimesh.smoothing\n",
        "import os\n",
        "\n",
        "# Load the exported GLB file\n",
        "output_filename = 'reconstructed_model.glb'\n",
        "if os.path.exists(output_filename):\n",
        "    # Load the scene\n",
        "    scene = trimesh.load(output_filename)\n",
        "    print(f\"Loaded {output_filename} as a Scene for refinement.\")\n",
        "\n",
        "    # Extract the mesh from the scene. Assuming the first geometry is the mesh.\n",
        "    # In a more complex scene, you might need a different approach to select the correct mesh.\n",
        "    if isinstance(scene, trimesh.Scene):\n",
        "        # Try to get the main mesh from the scene's geometry\n",
        "        mesh_list = list(scene.geometry.values())\n",
        "        if mesh_list:\n",
        "            reconstructed_mesh = mesh_list[0]\n",
        "            print(\"Extracted mesh from the loaded scene.\")\n",
        "        else:\n",
        "            reconstructed_mesh = None\n",
        "            print(\"No geometry found in the loaded scene.\")\n",
        "    else:\n",
        "        # If it's not a scene, assume it's already a mesh (though the error suggests otherwise)\n",
        "        reconstructed_mesh = scene\n",
        "        print(\"Loaded object is not a Scene, assuming it is a mesh.\")\n",
        "\n",
        "\n",
        "    if reconstructed_mesh is not None and isinstance(reconstructed_mesh, trimesh.Trimesh):\n",
        "        # --- Optional Refinement Steps ---\n",
        "\n",
        "        # 1. Remove smallest disconnected components (noise)\n",
        "        # Calculate the connected components\n",
        "        components = reconstructed_mesh.split(only_watertight=False)\n",
        "\n",
        "        if components:\n",
        "            # Sort components by number of faces (or vertices) and keep the largest\n",
        "            components.sort(key=lambda m: len(m.faces), reverse=True)\n",
        "            # Keep only the largest component(s) - adjust the number [:] as needed\n",
        "            reconstructed_mesh = components[0]\n",
        "            print(f\"Removed {len(components) - 1} smaller disconnected components.\")\n",
        "        else:\n",
        "            print(\"No disconnected components found or mesh is empty after loading.\")\n",
        "\n",
        "\n",
        "        # 2. Apply Laplacian smoothing\n",
        "        # Be cautious with iterations and lambda - too many can distort the shape\n",
        "        # reconstructed_mesh = trimesh.smoothing.filter_laplacian(reconstructed_mesh, iterations=5, lamb=0.1)\n",
        "        # print(\"Applied Laplacian smoothing.\")\n",
        "\n",
        "        # --- End of Optional Refinement Steps ---\n",
        "\n",
        "\n",
        "        # Export the refined mesh to a new GLB file\n",
        "        refined_output_filename = 'reconstructed_model_refined.glb'\n",
        "        reconstructed_mesh.export(refined_output_filename)\n",
        "        print(f\"Refined mesh saved as {refined_output_filename}\")\n",
        "    elif reconstructed_mesh is None:\n",
        "         print(\"No valid mesh object available for refinement.\")\n",
        "    else:\n",
        "         print(f\"Loaded object is of type {type(reconstructed_mesh)}, which is not a trimesh.Trimesh object. Cannot perform refinement.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(f\"Error: {output_filename} not found. Cannot perform refinement.\")\n",
        "\n",
        "# Note on testing with different silhouette sets:\n",
        "# To test the complete pipeline with different sets of silhouettes,\n",
        "# you would need to repeat the entire notebook execution starting from the\n",
        "# image upload step (Step 1: Preparar o ambiente e carregar dados) with\n",
        "# each new set of images. After execution, you would download and visually\n",
        "# inspect the 'reconstructed_model.glb' (or 'reconstructed_model_refined.glb')\n",
        "# file using an external 3D viewer for each test case."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b27da146"
      },
      "source": [
        "# How to Use the 3D Reconstruction Pipeline\n",
        "\n",
        "This notebook provides an automated pipeline to reconstruct a 3D model from multiple 2D silhouette images using the Visual Hull and Marching Cubes algorithms. Follow the steps below to use it:\n",
        "\n",
        "## Input Requirements\n",
        "\n",
        "1.  **Silhouette Images:** You need to provide multiple silhouette images of the object from different viewpoints.\n",
        "    *   **Format:** Images should be in common formats like PNG or JPEG.\n",
        "    *   **Content:** Each image should clearly show the object as a distinct silhouette against a uniform background. The current implementation assumes the object is represented by darker pixels and the background by lighter pixels, which are then thresholded to create a binary mask (silhouette) where the object is white (255) and the background is black (0).\n",
        "    *   **Number of Views:** The accuracy of the reconstruction improves with more views covering a full 360 degrees around the object. There is no strict minimum, but a diverse set of views is crucial.\n",
        "\n",
        "2.  **View Types:** You must provide a list of strings (`view_types`) that corresponds to the order of the uploaded images. This list indicates the assumed orientation of the camera for each image (e.g., 'front', 'side', 'top'). **The accuracy of the 3D reconstruction heavily depends on the correctness of this list matching the actual views.** The current simplified `project_voxel_to_silhouette` function supports 'front', 'side', and 'top' views, assuming simple orthogonal projections. For more complex view angles, this function and the `view_types` would need to be adapted (ideally using camera calibration parameters).\n",
        "\n",
        "## Configurable Options\n",
        "\n",
        "The main function `run_reconstruction_pipeline` has several parameters you can configure:\n",
        "\n",
        "*   `uploaded_files`: (Required) A dictionary containing the uploaded images (provided automatically by the upload step).\n",
        "*   `view_types`: (Required) A list of strings specifying the view type for each uploaded image, matching the upload order.\n",
        "*   `grid_size`: (Optional) An integer specifying the resolution of the 3D voxel grid (e.g., 100 for a 100x100x100 grid). A higher grid size results in a more detailed but computationally more expensive reconstruction. Default is 100.\n",
        "*   `volume_bounds`: (Optional) A dictionary defining the world coordinates (x_min, x_max, y_min, y_max, z_min, z_max) of the 3D volume where the reconstruction will occur. Adjust these bounds to encompass the expected size and location of your object in 3D space. Default is `{'x_min': -1.0, 'x_max': 1.0, 'y_min': -1.0, 'y_max': 1.0, 'z_min': -1.0, 'z_max': 1.0}`.\n",
        "*   `marching_cubes_level`: (Optional) A float value used by the Marching Cubes algorithm to determine the iso-surface for mesh generation. This level should typically be a value that separates the 'occupied' (object) voxels from the 'empty' (background) voxels. Given our binary voxel grid (0 or 255), a level of 0.5 (when treating the grid as boolean) or a value between 0 and 255 (when treating it as float) like 127 is commonly used. You might need to experiment with this value based on your specific voxel grid data. Default is 0.5 (used with boolean conversion).\n",
        "*   `show_previews`: (Optional) A boolean value (True or False) to enable or disable visual previews of the extracted silhouettes and slices of the computed voxel grid. Enabling previews helps in understanding the process and debugging issues. Default is True.\n",
        "\n",
        "## Expected Outputs\n",
        "\n",
        "The pipeline will output a 3D model in the `.glb` format.\n",
        "*   `reconstructed_model.glb`: This file contains the mesh generated directly from the visual hull voxel grid using Marching Cubes.\n",
        "*   `reconstructed_model_refined.glb` (Optional - if refinement steps are enabled): This file contains the mesh after applying optional refinement steps like removing small disconnected components.\n",
        "\n",
        "You can download these files from the Google Colab environment using the file browser on the left-hand side or by using the `files.download()` function (though the current pipeline code exports it directly).\n",
        "\n",
        "## How to Run the Pipeline\n",
        "\n",
        "After uploading your images using the file upload widget (Step 1 in the notebook), you can run the pipeline by calling the `run_reconstruction_pipeline` function.\n",
        "\n",
        "Make sure the `uploaded_files` variable is populated and define the `view_types` list corresponding to your uploaded images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "209a7d94"
      },
      "source": [
        "# Assuming 'uploaded_files' is already populated from the previous upload step\n",
        "# and 'example_view_types' is defined to match the number of uploaded images.\n",
        "# If not, please run the file upload cell first and define example_view_types.\n",
        "\n",
        "# Check if uploaded_files is defined and not empty before calling the pipeline\n",
        "if 'uploaded_files' in locals() and uploaded_files:\n",
        "    # Update the example_view_types to match the number of uploaded images\n",
        "    # This is still a placeholder; actual view types depend on the image capture.\n",
        "    example_view_types = [f'view{i+1}' for i in range(len(uploaded_files))]\n",
        "    print(f\"\\nUsing {len(uploaded_files)} uploaded images.\")\n",
        "    print(f\"Corresponding example view types: {example_view_types}\")\n",
        "\n",
        "    # Call the main pipeline function with visualizations enabled\n",
        "    # You can adjust the parameters here if needed\n",
        "    run_reconstruction_pipeline(\n",
        "        uploaded_files=uploaded_files,\n",
        "        view_types=example_view_types,\n",
        "        grid_size=150,  # Example: use a medium grid size\n",
        "        volume_bounds={'x_min': -1.5, 'x_max': 1.5, 'y_min': -1.5, 'y_max': 1.5, 'z_min': -1.5, 'z_max': 1.5}, # Example: adjust bounds\n",
        "        marching_cubes_level=127, # Example: use level 127\n",
        "        show_previews=True # Keep previews enabled\n",
        "    )\n",
        "else:\n",
        "    print(\"\\n'uploaded_files' is not defined or is empty.\")\n",
        "    print(\"Please execute the file upload cell first to upload your images.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42b41616"
      },
      "source": [
        "## Documentar o framework\n",
        "\n",
        "### Subtask:\n",
        "Add clear instructions on how to use the automated pipeline, explaining the input requirements (image formats, number of views, corresponding view types), configurable options, and expected outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7cbafba"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "repo_path = '/content/3D-Fusion-AI'\n",
        "\n",
        "# List of files and directories to remove\n",
        "items_to_remove = [\n",
        "    'vite.config.ts',\n",
        "    'package.json',\n",
        "    'index.tsx',\n",
        "    'package-lock.json',\n",
        "    'App.tsx',\n",
        "    '.git', # Hidden directory\n",
        "    '.gitignore',\n",
        "    'types.ts',\n",
        "    'tsconfig.json',\n",
        "    'index.html',\n",
        "    'components', # Directory\n",
        "    'src', # Directory\n",
        "    'PLANO_DE_PROJETO.md'\n",
        "]\n",
        "\n",
        "print(f\"Cleaning up directory: {repo_path}\")\n",
        "\n",
        "for item in items_to_remove:\n",
        "    item_path = os.path.join(repo_path, item)\n",
        "    if os.path.exists(item_path):\n",
        "        try:\n",
        "            if os.path.isdir(item_path):\n",
        "                shutil.rmtree(item_path)\n",
        "                print(f\"Removed directory: {item}\")\n",
        "            else:\n",
        "                os.remove(item_path)\n",
        "                print(f\"Removed file: {item}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error removing {item}: {e}\")\n",
        "    else:\n",
        "        print(f\"Item not found, skipping: {item}\")\n",
        "\n",
        "print(\"Cleanup complete.\")\n",
        "\n",
        "# Optional: List contents again to verify\n",
        "# print(f\"\\nContents of {repo_path} after cleanup:\")\n",
        "# if os.path.exists(repo_path):\n",
        "#     for item in os.listdir(repo_path):\n",
        "#         print(item)\n",
        "# else:\n",
        "#     print(f\"Directory not found: {repo_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cd8b526"
      },
      "source": [
        "import os\n",
        "\n",
        "# List files in the cloned repository directory\n",
        "repo_path = '/content/3D-Fusion-AI'\n",
        "if os.path.exists(repo_path):\n",
        "    print(f\"Contents of {repo_path}:\")\n",
        "    for item in os.listdir(repo_path):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Directory not found: {repo_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3cbb5bc"
      },
      "source": [
        "**Reasoning**:\n",
        "Add a Markdown cell with instructions on how to use the pipeline, including input requirements, configurable options, expected outputs, and an example usage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50fe170d"
      },
      "source": [
        "# Add a Markdown cell with the usage instructions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5be7420"
      },
      "source": [
        "**Reasoning**:\n",
        "Add a markdown cell with clear instructions on how to use the automated pipeline, explaining the input requirements, configurable options, and expected outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "769df0e6"
      },
      "source": [
        "# Create a new Markdown cell with instructions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1326a1c0"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a Markdown cell with instructions on how to use the pipeline, explaining input requirements, configurable options, and expected outputs, as well as providing an example code snippet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9de7e04f"
      },
      "source": [
        "# This is a markdown cell.\n",
        "# # How to Use the 3D Reconstruction Pipeline\n",
        "#\n",
        "# This notebook provides an automated pipeline to reconstruct a 3D model from multiple 2D silhouette images using the Visual Hull and Marching Cubes algorithms. Follow the steps below to use it:\n",
        "#\n",
        "# ## Input Requirements\n",
        "#\n",
        "# 1.  **Silhouette Images:** You need to provide multiple silhouette images of the object from different viewpoints.\n",
        "#     *   **Format:** Images should be in common formats like PNG or JPEG.\n",
        "#     *   **Content:** Each image should clearly show the object as a distinct silhouette against a uniform background. The current implementation assumes the object is represented by darker pixels and the background by lighter pixels, which are then thresholded to create a binary mask (silhouette) where the object is white (255) and the background is black (0).\n",
        "#     *   **Number of Views:** The accuracy of the reconstruction improves with more views covering a full 360 degrees around the object. There is no strict minimum, but a diverse set of views is crucial.\n",
        "#\n",
        "# 2.  **View Types:** You must provide a list of strings (`view_types`) that corresponds to the order of the uploaded images. This list indicates the assumed orientation of the camera for each image (e.g., 'front', 'side', 'top'). **The accuracy of the 3D reconstruction heavily depends on the correctness of this list matching the actual views.** The current simplified `project_voxel_to_silhouette` function supports 'front', 'side', and 'top' views, assuming simple orthogonal projections. For more complex view angles, this function and the `view_types` would need to be adapted (ideally using camera calibration parameters).\n",
        "#\n",
        "# ## Configurable Options\n",
        "#\n",
        "# The main function `run_reconstruction_pipeline` has several parameters you can configure:\n",
        "#\n",
        "# *   `uploaded_files`: (Required) A dictionary containing the uploaded images (provided automatically by the upload step).\n",
        "# *   `view_types`: (Required) A list of strings specifying the view type for each uploaded image, matching the upload order.\n",
        "# *   `grid_size`: (Optional) An integer specifying the resolution of the 3D voxel grid (e.g., 100 for a 100x100x100 grid). A higher grid size results in a more detailed but computationally more expensive reconstruction. Default is 100.\n",
        "# *   `volume_bounds`: (Optional) A dictionary defining the world coordinates (x_min, x_max, y_min, y_max, z_min, z_max) of the 3D volume where the reconstruction will occur. Adjust these bounds to encompass the expected size and location of your object in 3D space. Default is `{'x_min': -1.0, 'x_max': 1.0, 'y_min': -1.0, 'y_max': 1.0, 'z_min': -1.0, 'z_max': 1.0}`.\n",
        "# *   `marching_cubes_level`: (Optional) A float value used by the Marching Cubes algorithm to determine the iso-surface for mesh generation. This level should typically be a value that separates the 'occupied' (object) voxels from the 'empty' (background) voxels. Given our binary voxel grid (0 or 255), a level of 0.5 (when treating the grid as boolean) or a value between 0 and 255 (when treating it as float) like 127 is commonly used. You might need to experiment with this value based on your specific voxel grid data. Default is 0.5 (used with boolean conversion).\n",
        "# *   `show_previews`: (Optional) A boolean value (True or False) to enable or disable visual previews of the extracted silhouettes and slices of the computed voxel grid. Enabling previews helps in understanding the process and debugging issues. Default is True.\n",
        "#\n",
        "# ## Expected Outputs\n",
        "#\n",
        "# The pipeline will output a 3D model in the `.glb` format.\n",
        "# *   `reconstructed_model.glb`: This file contains the mesh generated directly from the visual hull voxel grid using Marching Cubes.\n",
        "# *   `reconstructed_model_refined.glb` (Optional - if refinement steps are enabled): This file contains the mesh after applying optional refinement steps like removing small disconnected components.\n",
        "#\n",
        "# You can download these files from the Google Colab environment using the file browser on the left-hand side or by using the `files.download()` function (though the current pipeline code exports it directly).\n",
        "#\n",
        "# ## How to Run the Pipeline\n",
        "#\n",
        "# After uploading your images using the file upload widget (Step 1 in the notebook), you can run the pipeline by calling the `run_reconstruction_pipeline` function.\n",
        "#\n",
        "# Make sure the `uploaded_files` variable is populated and define the `view_types` list corresponding to your uploaded images.\n",
        "#\n",
        "# ```python\n",
        "# # Example of how to call the pipeline function\n",
        "# # Assuming uploaded_files is populated from the file upload step\n",
        "# # Define your view types based on the images you uploaded\n",
        "# # This is a placeholder example - replace with your actual view types!\n",
        "# my_view_types = ['front', 'side', 'top', 'another_side', 'back', 'another_top'] # Example list\n",
        "#\n",
        "# # Check if uploaded_files is not empty before running\n",
        "# if uploaded_files:\n",
        "#     print(f\"Running pipeline with {len(uploaded_files)} images and {len(my_view_types)} view types.\")\n",
        "#     run_reconstruction_pipeline(\n",
        "#         uploaded_files=uploaded_files,\n",
        "#         view_types=my_view_types,\n",
        "#         grid_size=120,              # Optional: Adjust grid size\n",
        "#         volume_bounds={             # Optional: Adjust volume bounds\n",
        "#             'x_min': -1.2, 'x_max': 1.2,\n",
        "#             'y_min': -1.2, 'y_max': 1.2,\n",
        "#             'z_min': -1.2, 'z_max': 1.2\n",
        "#         },\n",
        "#         marching_cubes_level=0.5,   # Optional: Adjust Marching Cubes level\n",
        "#         show_previews=True          # Optional: Enable/disable previews\n",
        "#     )\n",
        "# else:\n",
        "#     print(\"No files uploaded. Please upload images first.\")\n",
        "# ```\n",
        "#\n",
        "# Remember to adjust the `my_view_types` list and the configurable options (`grid_size`, `volume_bounds`, `marching_cubes_level`, `show_previews`) according to your specific input images and desired reconstruction quality.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "104d9fdf"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "## Q&A\n",
        "\n",
        "There were no explicit questions asked in the task description.\n",
        "\n",
        "## Data Analysis Key Findings\n",
        "\n",
        "*   The existing code was successfully refactored into five distinct Python functions: `load_images`, `process_silhouettes`, `compute_visual_hull`, `generate_mesh`, and `export_mesh`, along with a helper function `project_voxel_to_silhouette`.\n",
        "*   Image uploading functionality was implemented for the Colab environment using `google.colab.files.upload()`, and an outline for handling image input in a web application was provided.\n",
        "*   A main function `run_reconstruction_pipeline` was created to orchestrate the sequence of operations, including loading, processing silhouettes, computing visual hull, generating mesh, and exporting.\n",
        "*   Visual feedback was added by modifying `process_silhouettes` and `compute_visual_hull` to display previews of extracted silhouettes and slices of the voxel grid, respectively, using `matplotlib.pyplot`. These visualizations displayed correctly within the Colab output.\n",
        "*   Error handling (`try...except` blocks) and detailed progress messages (`print` statements) were integrated into the pipeline functions to improve robustness and user feedback.\n",
        "*   The `run_reconstruction_pipeline` function was made configurable with parameters for `grid_size`, `volume_bounds`, `marching_cubes_level`, and `show_previews`.\n",
        "*   The mesh generation step using `skimage.measure.marching_cubes` consistently failed with a \"ValueError: Surface level must be within volume data range\", regardless of the input data type (uint8, boolean, float64) or the `level` parameter used (0, 0.5, 100, 127). This prevented the pipeline from completing successfully.\n",
        "*   Comprehensive documentation was added in a Markdown cell, explaining the input requirements, configurable options, expected outputs, and usage instructions for the pipeline.\n",
        "\n",
        "## Insights or Next Steps\n",
        "\n",
        "*   The primary next step is to diagnose and fix the persistent \"Surface level must be within volume data range\" error encountered during the `skimage.measure.marching_cubes` step to enable successful mesh generation and complete the 3D reconstruction pipeline.\n",
        "*   For the web application outline, the next step would be to build a backend service (e.g., using Flask or Django) that receives image data from the frontend and utilizes the developed Python functions to perform the 3D reconstruction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55f4f636"
      },
      "source": [
        "## Limpeza de Arquivos de Imagem\n",
        "\n",
        "Use a célula abaixo para remover arquivos de imagem carregados no diretório `/content/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a138313"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Directory to clean up extracted data\n",
        "extracted_data_dir = '/content/uploaded_data'\n",
        "\n",
        "print(f\"Cleaning up extracted data directory: {extracted_data_dir}\")\n",
        "\n",
        "# Check if the directory exists and remove it\n",
        "if os.path.exists(extracted_data_dir):\n",
        "    try:\n",
        "        shutil.rmtree(extracted_data_dir)\n",
        "        print(f\"Directory '{extracted_data_dir}' e seu conteúdo removidos com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error removing directory '{extracted_data_dir}': {e}\")\n",
        "else:\n",
        "    print(f\"Directory '{extracted_data_dir}' não encontrado, nada para limpar.\")\n",
        "\n",
        "# The old logic for cleaning individual images in /content/ might still be useful,\n",
        "# but let's prioritize cleaning the extracted data directory.\n",
        "# Keeping the old logic commented out or separate for now.\n",
        "\n",
        "# # Directory to clean up\n",
        "# cleanup_dir = '/content/'\n",
        "# # List of common image file extensions to remove\n",
        "# image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']\n",
        "#\n",
        "# print(f\"Cleaning up image files in: {cleanup_dir}\")\n",
        "#\n",
        "# # Iterate through items in the directory\n",
        "# for item in os.listdir(cleanup_dir):\n",
        "#     item_path = os.path.join(cleanup_dir, item)\n",
        "#     # Check if it's a file and has an image extension\n",
        "#     if os.path.isfile(item_path) and os.path.splitext(item)[1].lower() in image_extensions:\n",
        "#         try:\n",
        "#             os.remove(item_path)\n",
        "#             print(f\"Removed image file: {item}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error removing {item}: {e}\")\n",
        "#\n",
        "# print(\"Image file cleanup complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3374b9d1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because it was waiting for user input that was interrupted. I need to modify the code to handle multiple file uploads and store them, then print a message if no files are uploaded.\n",
        "\n"
      ]
    }
  ]
}